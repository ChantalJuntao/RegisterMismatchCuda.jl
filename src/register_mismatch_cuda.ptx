//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Thu Sep  4 23:40:32 2014 (1409892032)
// Cuda compilation tools, release 6.5, V6.5.19
//

.version 4.1
.target sm_20
.address_size 64

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.const .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .func _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm(
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_0,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_1,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_2,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_3,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_4,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_5,
	.param .b64 _Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .s32 	%r<37>;
	.reg .s64 	%rd<30>;
	.reg .f64 	%fd<8>;


	ld.param.u64 	%rd9, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_0];
	ld.param.u64 	%rd10, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_1];
	ld.param.u64 	%rd11, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_2];
	ld.param.u64 	%rd12, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_3];
	ld.param.u64 	%rd13, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_4];
	ld.param.u64 	%rd14, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_5];
	ld.param.u64 	%rd15, [_Z22kernel_conv_componentsIdEvPT_S1_S1_mmmm_param_6];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r34, %r11, %r12, %r13;
	cvt.s64.s32	%rd29, %r34;
	setp.ge.u64	%p1, %rd29, %rd14;
	@%p1 bra 	BB0_11;

	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r17, %r15, %r14, %r16;
	cvt.s64.s32	%rd2, %r17;
	mov.u32 	%r18, %nctaid.x;
	mul.lo.s32 	%r2, %r18, %r15;

BB0_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r35, %r20, %r19, %r21;
	cvt.s64.s32	%rd16, %r35;
	setp.ge.u64	%p2, %rd16, %rd13;
	@%p2 bra 	BB0_10;

	mul.lo.s64 	%rd4, %rd29, %rd13;

BB0_4:
	setp.ge.u64	%p3, %rd2, %rd12;
	@%p3 bra 	BB0_9;

	cvt.u64.u32	%rd17, %r35;
	add.s64 	%rd18, %rd17, %rd4;
	cvt.s64.s32 	%rd19, %rd18;
	mul.lo.s64 	%rd5, %rd19, %rd15;
	mov.u32 	%r36, %r17;

BB0_6:
	mov.u32 	%r7, %r36;
	cvt.u64.u32	%rd20, %r7;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd6, %rd21;
	shl.b64 	%rd22, %rd6, 3;
	add.s64 	%rd7, %rd9, %rd22;
	ld.f64 	%fd7, [%rd7];
	abs.f64 	%fd2, %fd7;
	setp.le.f64	%p4, %fd2, 0d7FF0000000000000;
	@%p4 bra 	BB0_8;

	mov.u64 	%rd23, 0;
	st.u64 	[%rd7], %rd23;
	mov.f64 	%fd7, 0d0000000000000000;

BB0_8:
	selp.u32	%r29, 1, 0, %p4;
	cvt.rn.f64.s32	%fd5, %r29;
	add.s64 	%rd25, %rd11, %rd22;
	st.f64 	[%rd25], %fd5;
	add.s64 	%rd26, %rd10, %rd22;
	mul.f64 	%fd6, %fd7, %fd7;
	st.f64 	[%rd26], %fd6;
	add.s32 	%r8, %r2, %r7;
	cvt.s64.s32	%rd27, %r8;
	setp.lt.u64	%p6, %rd27, %rd12;
	mov.u32 	%r36, %r8;
	@%p6 bra 	BB0_6;

BB0_9:
	mov.u32 	%r30, %nctaid.y;
	mad.lo.s32 	%r35, %r30, %r20, %r35;
	cvt.s64.s32	%rd28, %r35;
	setp.lt.u64	%p7, %rd28, %rd13;
	@%p7 bra 	BB0_4;

BB0_10:
	mov.u32 	%r32, %nctaid.z;
	mad.lo.s32 	%r34, %r32, %r11, %r34;
	cvt.s64.s32	%rd29, %r34;
	setp.lt.u64	%p8, %rd29, %rd14;
	@%p8 bra 	BB0_2;

BB0_11:
	ret;
}

.visible .func _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm(
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_0,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_1,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_2,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_3,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_4,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_5,
	.param .b64 _Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .s32 	%r<38>;
	.reg .f32 	%f<8>;
	.reg .s64 	%rd<29>;


	ld.param.u64 	%rd9, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_0];
	ld.param.u64 	%rd10, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_1];
	ld.param.u64 	%rd11, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_2];
	ld.param.u64 	%rd12, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_3];
	ld.param.u64 	%rd13, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_4];
	ld.param.u64 	%rd14, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_5];
	ld.param.u64 	%rd15, [_Z22kernel_conv_componentsIfEvPT_S1_S1_mmmm_param_6];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r35, %r11, %r12, %r13;
	cvt.s64.s32	%rd28, %r35;
	setp.ge.u64	%p1, %rd28, %rd14;
	@%p1 bra 	BB1_11;

	mov.u32 	%r14, %ctaid.x;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r17, %r15, %r14, %r16;
	cvt.s64.s32	%rd2, %r17;
	mov.u32 	%r18, %nctaid.x;
	mul.lo.s32 	%r2, %r18, %r15;

BB1_2:
	mov.u32 	%r19, %ctaid.y;
	mov.u32 	%r20, %ntid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r36, %r20, %r19, %r21;
	cvt.s64.s32	%rd16, %r36;
	setp.ge.u64	%p2, %rd16, %rd13;
	@%p2 bra 	BB1_10;

	mul.lo.s64 	%rd4, %rd28, %rd13;

BB1_4:
	setp.ge.u64	%p3, %rd2, %rd12;
	@%p3 bra 	BB1_9;

	cvt.u64.u32	%rd17, %r36;
	add.s64 	%rd18, %rd17, %rd4;
	cvt.s64.s32 	%rd19, %rd18;
	mul.lo.s64 	%rd5, %rd19, %rd15;
	mov.u32 	%r37, %r17;

BB1_6:
	mov.u32 	%r7, %r37;
	cvt.u64.u32	%rd20, %r7;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd6, %rd21;
	shl.b64 	%rd22, %rd6, 2;
	add.s64 	%rd7, %rd9, %rd22;
	ld.f32 	%f7, [%rd7];
	abs.f32 	%f2, %f7;
	setp.le.f32	%p4, %f2, 0f7F800000;
	@%p4 bra 	BB1_8;

	mov.u32 	%r29, 0;
	st.u32 	[%rd7], %r29;
	mov.f32 	%f7, 0f00000000;

BB1_8:
	selp.u32	%r30, 1, 0, %p4;
	cvt.rn.f32.s32	%f5, %r30;
	add.s64 	%rd24, %rd11, %rd22;
	st.f32 	[%rd24], %f5;
	add.s64 	%rd25, %rd10, %rd22;
	mul.f32 	%f6, %f7, %f7;
	st.f32 	[%rd25], %f6;
	add.s32 	%r8, %r2, %r7;
	cvt.s64.s32	%rd26, %r8;
	setp.lt.u64	%p6, %rd26, %rd12;
	mov.u32 	%r37, %r8;
	@%p6 bra 	BB1_6;

BB1_9:
	mov.u32 	%r31, %nctaid.y;
	mad.lo.s32 	%r36, %r31, %r20, %r36;
	cvt.s64.s32	%rd27, %r36;
	setp.lt.u64	%p7, %rd27, %rd13;
	@%p7 bra 	BB1_4;

BB1_10:
	mov.u32 	%r33, %nctaid.z;
	mad.lo.s32 	%r35, %r33, %r11, %r35;
	cvt.s64.s32	%rd28, %r35;
	setp.lt.u64	%p8, %rd28, %rd14;
	@%p8 bra 	BB1_2;

BB1_11:
	ret;
}

.visible .func _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm(
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10,
	.param .b64 _Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<32>;
	.reg .s64 	%rd<38>;
	.reg .f64 	%fd<49>;


	ld.param.u64 	%rd8, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0];
	ld.param.u64 	%rd9, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1];
	ld.param.u64 	%rd10, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2];
	ld.param.u64 	%rd11, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3];
	ld.param.u64 	%rd12, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4];
	ld.param.u64 	%rd13, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5];
	ld.param.u64 	%rd14, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6];
	ld.param.u64 	%rd15, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7];
	ld.param.u64 	%rd16, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8];
	ld.param.u64 	%rd17, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9];
	ld.param.u64 	%rd18, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10];
	ld.param.u64 	%rd19, [_Z29kernel_calcNumDenom_intensityI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11];
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r2, %r1, %r15, %r16;
	mov.u32 	%r3, %ntid.z;
	mov.u32 	%r17, %ctaid.z;
	mov.u32 	%r18, %tid.z;
	mad.lo.s32 	%r29, %r3, %r17, %r18;
	cvt.s64.s32	%rd37, %r29;
	setp.ge.u64	%p1, %rd37, %rd18;
	@%p1 bra 	BB2_9;

	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r22, %r19, %r20, %r21;
	cvt.s64.s32	%rd2, %r22;
	mov.u32 	%r23, %nctaid.z;
	mul.lo.s32 	%r5, %r23, %r3;
	cvt.s64.s32	%rd3, %r2;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r6, %r24, %r19;
	mov.u32 	%r25, %nctaid.x;
	mul.lo.s32 	%r7, %r25, %r1;

BB2_2:
	setp.ge.u64	%p2, %rd2, %rd17;
	@%p2 bra 	BB2_8;

	mul.lo.s64 	%rd5, %rd37, %rd17;
	mov.u32 	%r30, %r22;

BB2_4:
	mov.u32 	%r10, %r30;
	setp.ge.u64	%p3, %rd3, %rd16;
	@%p3 bra 	BB2_7;

	cvt.u64.u32	%rd20, %r10;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd22, %rd21;
	mul.lo.s64 	%rd6, %rd22, %rd19;
	mov.u32 	%r31, %r2;

BB2_6:
	mov.u32 	%r11, %r31;
	cvt.u64.u32	%rd23, %r11;
	add.s64 	%rd24, %rd23, %rd6;
	cvt.s64.s32 	%rd25, %rd24;
	shl.b64 	%rd26, %rd25, 4;
	add.s64 	%rd27, %rd9, %rd26;
	ld.v2.f64 	{%fd1, %fd2}, [%rd27];
	add.s64 	%rd28, %rd13, %rd26;
	ld.v2.f64 	{%fd3, %fd4}, [%rd28];
	mul.f64 	%fd7, %fd4, %fd2;
	fma.rn.f64 	%fd10, %fd1, %fd3, %fd7;
	mul.f64 	%fd11, %fd1, %fd4;
	mul.f64 	%fd12, %fd3, %fd2;
	sub.f64 	%fd13, %fd11, %fd12;
	add.s64 	%rd29, %rd10, %rd26;
	ld.v2.f64 	{%fd14, %fd15}, [%rd29];
	add.s64 	%rd30, %rd12, %rd26;
	ld.v2.f64 	{%fd16, %fd17}, [%rd30];
	mul.f64 	%fd20, %fd17, %fd15;
	fma.rn.f64 	%fd23, %fd14, %fd16, %fd20;
	mul.f64 	%fd24, %fd14, %fd17;
	mul.f64 	%fd25, %fd16, %fd15;
	sub.f64 	%fd26, %fd24, %fd25;
	add.s64 	%rd31, %rd8, %rd26;
	ld.v2.f64 	{%fd27, %fd28}, [%rd31];
	add.s64 	%rd32, %rd11, %rd26;
	ld.v2.f64 	{%fd29, %fd30}, [%rd32];
	mul.f64 	%fd33, %fd30, %fd28;
	fma.rn.f64 	%fd36, %fd27, %fd29, %fd33;
	mul.f64 	%fd37, %fd27, %fd30;
	mul.f64 	%fd38, %fd29, %fd28;
	sub.f64 	%fd39, %fd37, %fd38;
	add.f64 	%fd40, %fd36, %fd36;
	mul.f64 	%fd41, %fd39, 0d0000000000000000;
	sub.f64 	%fd42, %fd40, %fd41;
	mul.f64 	%fd43, %fd36, 0d0000000000000000;
	fma.rn.f64 	%fd44, %fd39, 0d4000000000000000, %fd43;
	add.s64 	%rd33, %rd14, %rd26;
	add.s64 	%rd34, %rd15, %rd26;
	add.s32 	%r12, %r7, %r11;
	cvt.s64.s32	%rd35, %r12;
	setp.lt.u64	%p4, %rd35, %rd16;
	add.f64 	%fd45, %fd13, %fd26;
	sub.f64 	%fd46, %fd45, %fd44;
	add.f64 	%fd47, %fd10, %fd23;
	sub.f64 	%fd48, %fd47, %fd42;
	st.v2.f64 	[%rd33], {%fd48, %fd46};
	st.v2.f64 	[%rd34], {%fd47, %fd45};
	mov.u32 	%r31, %r12;
	@%p4 bra 	BB2_6;

BB2_7:
	add.s32 	%r13, %r6, %r10;
	cvt.s64.s32	%rd36, %r13;
	setp.lt.u64	%p5, %rd36, %rd17;
	mov.u32 	%r30, %r13;
	@%p5 bra 	BB2_4;

BB2_8:
	add.s32 	%r29, %r5, %r29;
	cvt.s64.s32	%rd37, %r29;
	setp.lt.u64	%p6, %rd37, %rd18;
	@%p6 bra 	BB2_2;

BB2_9:
	ret;
}

.visible .func _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm(
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10,
	.param .b64 _Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<32>;
	.reg .f32 	%f<49>;
	.reg .s64 	%rd<38>;


	ld.param.u64 	%rd8, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0];
	ld.param.u64 	%rd9, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1];
	ld.param.u64 	%rd10, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2];
	ld.param.u64 	%rd11, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3];
	ld.param.u64 	%rd12, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4];
	ld.param.u64 	%rd13, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5];
	ld.param.u64 	%rd14, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6];
	ld.param.u64 	%rd15, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7];
	ld.param.u64 	%rd16, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8];
	ld.param.u64 	%rd17, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9];
	ld.param.u64 	%rd18, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10];
	ld.param.u64 	%rd19, [_Z29kernel_calcNumDenom_intensityI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11];
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r2, %r1, %r15, %r16;
	mov.u32 	%r3, %ntid.z;
	mov.u32 	%r17, %ctaid.z;
	mov.u32 	%r18, %tid.z;
	mad.lo.s32 	%r29, %r3, %r17, %r18;
	cvt.s64.s32	%rd37, %r29;
	setp.ge.u64	%p1, %rd37, %rd18;
	@%p1 bra 	BB3_9;

	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r22, %r19, %r20, %r21;
	cvt.s64.s32	%rd2, %r22;
	mov.u32 	%r23, %nctaid.z;
	mul.lo.s32 	%r5, %r23, %r3;
	cvt.s64.s32	%rd3, %r2;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r6, %r24, %r19;
	mov.u32 	%r25, %nctaid.x;
	mul.lo.s32 	%r7, %r25, %r1;

BB3_2:
	setp.ge.u64	%p2, %rd2, %rd17;
	@%p2 bra 	BB3_8;

	mul.lo.s64 	%rd5, %rd37, %rd17;
	mov.u32 	%r30, %r22;

BB3_4:
	mov.u32 	%r10, %r30;
	setp.ge.u64	%p3, %rd3, %rd16;
	@%p3 bra 	BB3_7;

	cvt.u64.u32	%rd20, %r10;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd22, %rd21;
	mul.lo.s64 	%rd6, %rd22, %rd19;
	mov.u32 	%r31, %r2;

BB3_6:
	mov.u32 	%r11, %r31;
	cvt.u64.u32	%rd23, %r11;
	add.s64 	%rd24, %rd23, %rd6;
	cvt.s64.s32 	%rd25, %rd24;
	shl.b64 	%rd26, %rd25, 3;
	add.s64 	%rd27, %rd9, %rd26;
	ld.v2.f32 	{%f1, %f2}, [%rd27];
	add.s64 	%rd28, %rd13, %rd26;
	ld.v2.f32 	{%f3, %f4}, [%rd28];
	mul.f32 	%f7, %f4, %f2;
	fma.rn.f32 	%f10, %f1, %f3, %f7;
	mul.f32 	%f11, %f1, %f4;
	mul.f32 	%f12, %f3, %f2;
	sub.f32 	%f13, %f11, %f12;
	add.s64 	%rd29, %rd10, %rd26;
	ld.v2.f32 	{%f14, %f15}, [%rd29];
	add.s64 	%rd30, %rd12, %rd26;
	ld.v2.f32 	{%f16, %f17}, [%rd30];
	mul.f32 	%f20, %f17, %f15;
	fma.rn.f32 	%f23, %f14, %f16, %f20;
	mul.f32 	%f24, %f14, %f17;
	mul.f32 	%f25, %f16, %f15;
	sub.f32 	%f26, %f24, %f25;
	add.s64 	%rd31, %rd8, %rd26;
	ld.v2.f32 	{%f27, %f28}, [%rd31];
	add.s64 	%rd32, %rd11, %rd26;
	ld.v2.f32 	{%f29, %f30}, [%rd32];
	mul.f32 	%f33, %f30, %f28;
	fma.rn.f32 	%f36, %f27, %f29, %f33;
	mul.f32 	%f37, %f27, %f30;
	mul.f32 	%f38, %f29, %f28;
	sub.f32 	%f39, %f37, %f38;
	add.f32 	%f40, %f36, %f36;
	mul.f32 	%f41, %f39, 0f00000000;
	sub.f32 	%f42, %f40, %f41;
	mul.f32 	%f43, %f36, 0f00000000;
	fma.rn.f32 	%f44, %f39, 0f40000000, %f43;
	add.s64 	%rd33, %rd14, %rd26;
	add.s64 	%rd34, %rd15, %rd26;
	add.s32 	%r12, %r7, %r11;
	cvt.s64.s32	%rd35, %r12;
	setp.lt.u64	%p4, %rd35, %rd16;
	add.f32 	%f45, %f13, %f26;
	sub.f32 	%f46, %f45, %f44;
	add.f32 	%f47, %f10, %f23;
	sub.f32 	%f48, %f47, %f42;
	st.v2.f32 	[%rd33], {%f48, %f46};
	st.v2.f32 	[%rd34], {%f47, %f45};
	mov.u32 	%r31, %r12;
	@%p4 bra 	BB3_6;

BB3_7:
	add.s32 	%r13, %r6, %r10;
	cvt.s64.s32	%rd36, %r13;
	setp.lt.u64	%p5, %rd36, %rd17;
	mov.u32 	%r30, %r13;
	@%p5 bra 	BB3_4;

BB3_8:
	add.s32 	%r29, %r5, %r29;
	cvt.s64.s32	%rd37, %r29;
	setp.lt.u64	%p6, %rd37, %rd18;
	@%p6 bra 	BB3_2;

BB3_9:
	ret;
}

.visible .func _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm(
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<32>;
	.reg .s64 	%rd<38>;
	.reg .f64 	%fd<62>;


	ld.param.u64 	%rd8, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0];
	ld.param.u64 	%rd9, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1];
	ld.param.u64 	%rd10, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2];
	ld.param.u64 	%rd11, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3];
	ld.param.u64 	%rd12, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4];
	ld.param.u64 	%rd13, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5];
	ld.param.u64 	%rd14, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6];
	ld.param.u64 	%rd15, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7];
	ld.param.u64 	%rd16, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8];
	ld.param.u64 	%rd17, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9];
	ld.param.u64 	%rd18, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10];
	ld.param.u64 	%rd19, [_Z26kernel_calcNumDenom_pixelsI7double2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11];
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r2, %r1, %r15, %r16;
	mov.u32 	%r3, %ntid.z;
	mov.u32 	%r17, %ctaid.z;
	mov.u32 	%r18, %tid.z;
	mad.lo.s32 	%r29, %r3, %r17, %r18;
	cvt.s64.s32	%rd37, %r29;
	setp.ge.u64	%p1, %rd37, %rd18;
	@%p1 bra 	BB4_9;

	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r22, %r19, %r20, %r21;
	cvt.s64.s32	%rd2, %r22;
	mov.u32 	%r23, %nctaid.z;
	mul.lo.s32 	%r5, %r23, %r3;
	cvt.s64.s32	%rd3, %r2;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r6, %r24, %r19;
	mov.u32 	%r25, %nctaid.x;
	mul.lo.s32 	%r7, %r25, %r1;

BB4_2:
	setp.ge.u64	%p2, %rd2, %rd17;
	@%p2 bra 	BB4_8;

	mul.lo.s64 	%rd5, %rd37, %rd17;
	mov.u32 	%r30, %r22;

BB4_4:
	mov.u32 	%r10, %r30;
	setp.ge.u64	%p3, %rd3, %rd16;
	@%p3 bra 	BB4_7;

	cvt.u64.u32	%rd20, %r10;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd22, %rd21;
	mul.lo.s64 	%rd6, %rd22, %rd19;
	mov.u32 	%r31, %r2;

BB4_6:
	mov.u32 	%r11, %r31;
	cvt.u64.u32	%rd23, %r11;
	add.s64 	%rd24, %rd23, %rd6;
	cvt.s64.s32 	%rd25, %rd24;
	shl.b64 	%rd26, %rd25, 4;
	add.s64 	%rd27, %rd8, %rd26;
	ld.v2.f64 	{%fd1, %fd2}, [%rd27];
	mul.f64 	%fd5, %fd2, 0d0000000000000000;
	fma.rn.f64 	%fd6, %fd1, 0dC000000000000000, %fd5;
	mul.f64 	%fd7, %fd1, 0d0000000000000000;
	mul.f64 	%fd8, %fd2, 0dC000000000000000;
	sub.f64 	%fd9, %fd7, %fd8;
	add.s64 	%rd28, %rd11, %rd26;
	ld.v2.f64 	{%fd10, %fd11}, [%rd28];
	mul.f64 	%fd13, %fd6, %fd10;
	mul.f64 	%fd15, %fd9, %fd11;
	sub.f64 	%fd16, %fd13, %fd15;
	mul.f64 	%fd17, %fd9, %fd10;
	fma.rn.f64 	%fd18, %fd6, %fd11, %fd17;
	add.s64 	%rd29, %rd10, %rd26;
	ld.v2.f64 	{%fd19, %fd20}, [%rd29];
	add.s64 	%rd30, %rd12, %rd26;
	ld.v2.f64 	{%fd21, %fd22}, [%rd30];
	mul.f64 	%fd25, %fd22, %fd20;
	fma.rn.f64 	%fd28, %fd19, %fd21, %fd25;
	mul.f64 	%fd29, %fd19, %fd22;
	mul.f64 	%fd30, %fd21, %fd20;
	sub.f64 	%fd31, %fd29, %fd30;
	add.f64 	%fd32, %fd16, %fd28;
	add.f64 	%fd33, %fd18, %fd31;
	add.s64 	%rd31, %rd9, %rd26;
	ld.v2.f64 	{%fd34, %fd35}, [%rd31];
	add.s64 	%rd32, %rd13, %rd26;
	ld.v2.f64 	{%fd36, %fd37}, [%rd32];
	mul.f64 	%fd40, %fd37, %fd35;
	fma.rn.f64 	%fd43, %fd34, %fd36, %fd40;
	mul.f64 	%fd44, %fd34, %fd37;
	mul.f64 	%fd45, %fd36, %fd35;
	sub.f64 	%fd46, %fd44, %fd45;
	add.s64 	%rd33, %rd14, %rd26;
	add.f64 	%fd47, %fd33, %fd46;
	add.f64 	%fd48, %fd32, %fd43;
	st.v2.f64 	[%rd33], {%fd48, %fd47};
	ld.v2.f64 	{%fd49, %fd50}, [%rd29];
	ld.v2.f64 	{%fd51, %fd52}, [%rd32];
	mul.f64 	%fd55, %fd49, %fd52;
	add.s64 	%rd34, %rd15, %rd26;
	add.s32 	%r12, %r7, %r11;
	cvt.s64.s32	%rd35, %r12;
	setp.lt.u64	%p4, %rd35, %rd16;
	mul.f64 	%fd58, %fd51, %fd50;
	sub.f64 	%fd59, %fd55, %fd58;
	mul.f64 	%fd60, %fd52, %fd50;
	fma.rn.f64 	%fd61, %fd49, %fd51, %fd60;
	st.v2.f64 	[%rd34], {%fd61, %fd59};
	mov.u32 	%r31, %r12;
	@%p4 bra 	BB4_6;

BB4_7:
	add.s32 	%r13, %r6, %r10;
	cvt.s64.s32	%rd36, %r13;
	setp.lt.u64	%p5, %rd36, %rd17;
	mov.u32 	%r30, %r13;
	@%p5 bra 	BB4_4;

BB4_8:
	add.s32 	%r29, %r5, %r29;
	cvt.s64.s32	%rd37, %r29;
	setp.lt.u64	%p6, %rd37, %rd18;
	@%p6 bra 	BB4_2;

BB4_9:
	ret;
}

.visible .func _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm(
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10,
	.param .b64 _Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<32>;
	.reg .f32 	%f<62>;
	.reg .s64 	%rd<38>;


	ld.param.u64 	%rd8, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_0];
	ld.param.u64 	%rd9, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_1];
	ld.param.u64 	%rd10, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_2];
	ld.param.u64 	%rd11, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_3];
	ld.param.u64 	%rd12, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_4];
	ld.param.u64 	%rd13, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_5];
	ld.param.u64 	%rd14, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_6];
	ld.param.u64 	%rd15, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_7];
	ld.param.u64 	%rd16, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_8];
	ld.param.u64 	%rd17, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_9];
	ld.param.u64 	%rd18, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_10];
	ld.param.u64 	%rd19, [_Z26kernel_calcNumDenom_pixelsI6float2EvPT_S2_S2_S2_S2_S2_S2_S2_mmmm_param_11];
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r2, %r1, %r15, %r16;
	mov.u32 	%r3, %ntid.z;
	mov.u32 	%r17, %ctaid.z;
	mov.u32 	%r18, %tid.z;
	mad.lo.s32 	%r29, %r3, %r17, %r18;
	cvt.s64.s32	%rd37, %r29;
	setp.ge.u64	%p1, %rd37, %rd18;
	@%p1 bra 	BB5_9;

	mov.u32 	%r19, %ntid.y;
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %tid.y;
	mad.lo.s32 	%r22, %r19, %r20, %r21;
	cvt.s64.s32	%rd2, %r22;
	mov.u32 	%r23, %nctaid.z;
	mul.lo.s32 	%r5, %r23, %r3;
	cvt.s64.s32	%rd3, %r2;
	mov.u32 	%r24, %nctaid.y;
	mul.lo.s32 	%r6, %r24, %r19;
	mov.u32 	%r25, %nctaid.x;
	mul.lo.s32 	%r7, %r25, %r1;

BB5_2:
	setp.ge.u64	%p2, %rd2, %rd17;
	@%p2 bra 	BB5_8;

	mul.lo.s64 	%rd5, %rd37, %rd17;
	mov.u32 	%r30, %r22;

BB5_4:
	mov.u32 	%r10, %r30;
	setp.ge.u64	%p3, %rd3, %rd16;
	@%p3 bra 	BB5_7;

	cvt.u64.u32	%rd20, %r10;
	add.s64 	%rd21, %rd20, %rd5;
	cvt.s64.s32 	%rd22, %rd21;
	mul.lo.s64 	%rd6, %rd22, %rd19;
	mov.u32 	%r31, %r2;

BB5_6:
	mov.u32 	%r11, %r31;
	cvt.u64.u32	%rd23, %r11;
	add.s64 	%rd24, %rd23, %rd6;
	cvt.s64.s32 	%rd25, %rd24;
	shl.b64 	%rd26, %rd25, 3;
	add.s64 	%rd27, %rd8, %rd26;
	ld.v2.f32 	{%f1, %f2}, [%rd27];
	mul.f32 	%f5, %f2, 0f00000000;
	fma.rn.f32 	%f6, %f1, 0fC0000000, %f5;
	mul.f32 	%f7, %f1, 0f00000000;
	mul.f32 	%f8, %f2, 0fC0000000;
	sub.f32 	%f9, %f7, %f8;
	add.s64 	%rd28, %rd11, %rd26;
	ld.v2.f32 	{%f10, %f11}, [%rd28];
	mul.f32 	%f13, %f6, %f10;
	mul.f32 	%f15, %f9, %f11;
	sub.f32 	%f16, %f13, %f15;
	mul.f32 	%f17, %f9, %f10;
	fma.rn.f32 	%f18, %f6, %f11, %f17;
	add.s64 	%rd29, %rd10, %rd26;
	ld.v2.f32 	{%f19, %f20}, [%rd29];
	add.s64 	%rd30, %rd12, %rd26;
	ld.v2.f32 	{%f21, %f22}, [%rd30];
	mul.f32 	%f25, %f22, %f20;
	fma.rn.f32 	%f28, %f19, %f21, %f25;
	mul.f32 	%f29, %f19, %f22;
	mul.f32 	%f30, %f21, %f20;
	sub.f32 	%f31, %f29, %f30;
	add.f32 	%f32, %f16, %f28;
	add.f32 	%f33, %f18, %f31;
	add.s64 	%rd31, %rd9, %rd26;
	ld.v2.f32 	{%f34, %f35}, [%rd31];
	add.s64 	%rd32, %rd13, %rd26;
	ld.v2.f32 	{%f36, %f37}, [%rd32];
	mul.f32 	%f40, %f37, %f35;
	fma.rn.f32 	%f43, %f34, %f36, %f40;
	mul.f32 	%f44, %f34, %f37;
	mul.f32 	%f45, %f36, %f35;
	sub.f32 	%f46, %f44, %f45;
	add.s64 	%rd33, %rd14, %rd26;
	add.f32 	%f47, %f33, %f46;
	add.f32 	%f48, %f32, %f43;
	st.v2.f32 	[%rd33], {%f48, %f47};
	ld.v2.f32 	{%f49, %f50}, [%rd29];
	ld.v2.f32 	{%f51, %f52}, [%rd32];
	mul.f32 	%f55, %f49, %f52;
	add.s64 	%rd34, %rd15, %rd26;
	add.s32 	%r12, %r7, %r11;
	cvt.s64.s32	%rd35, %r12;
	setp.lt.u64	%p4, %rd35, %rd16;
	mul.f32 	%f58, %f51, %f50;
	sub.f32 	%f59, %f55, %f58;
	mul.f32 	%f60, %f52, %f50;
	fma.rn.f32 	%f61, %f49, %f51, %f60;
	st.v2.f32 	[%rd34], {%f61, %f59};
	mov.u32 	%r31, %r12;
	@%p4 bra 	BB5_6;

BB5_7:
	add.s32 	%r13, %r6, %r10;
	cvt.s64.s32	%rd36, %r13;
	setp.lt.u64	%p5, %rd36, %rd17;
	mov.u32 	%r30, %r13;
	@%p5 bra 	BB5_4;

BB5_8:
	add.s32 	%r29, %r5, %r29;
	cvt.s64.s32	%rd37, %r29;
	setp.lt.u64	%p6, %rd37, %rd18;
	@%p6 bra 	BB5_2;

BB5_9:
	ret;
}

.visible .func _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm(
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_0,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_1,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_2,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_3,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_4,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_5,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_6,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_7,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_8,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_9,
	.param .b64 _Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_10
)
{
	.local .align 4 .b8 	__local_depot6[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .s32 	%r<55>;
	.reg .s64 	%rd<41>;
	.reg .f64 	%fd<121>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd5, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_0];
	ld.param.u64 	%rd6, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_1];
	ld.param.f64 	%fd33, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_2];
	ld.param.f64 	%fd34, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_3];
	ld.param.f64 	%fd35, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_4];
	ld.param.u64 	%rd7, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_5];
	ld.param.u64 	%rd8, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_6];
	ld.param.u64 	%rd9, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_7];
	ld.param.u64 	%rd10, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_8];
	ld.param.u64 	%rd11, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_9];
	ld.param.u64 	%rd12, [_Z14kernel_fdshiftI7double2dEvPT_S2_T0_S3_S3_mmmmmm_param_10];
	mov.u32 	%r17, %ntid.z;
	mov.u32 	%r18, %ctaid.z;
	mov.u32 	%r19, %tid.z;
	mad.lo.s32 	%r50, %r17, %r18, %r19;
	cvt.s64.s32	%rd40, %r50;
	setp.ge.u64	%p1, %rd40, %rd10;
	@%p1 bra 	BB6_25;

	cvt.rn.f64.u64	%fd36, %rd7;
	mul.f64 	%fd37, %fd33, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd37, %fd36;
	cvt.rn.f64.u64	%fd38, %rd9;
	mul.f64 	%fd39, %fd34, 0d401921FB54442D18;
	div.rn.f64 	%fd2, %fd39, %fd38;
	cvt.rn.f64.u64	%fd40, %rd10;
	mul.f64 	%fd41, %fd35, 0d401921FB54442D18;
	div.rn.f64 	%fd3, %fd41, %fd40;
	cvt.rn.f64.u64	%fd4, %rd12;

BB6_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r51, %r21, %r20, %r22;
	cvt.s64.s32	%rd13, %r51;
	setp.ge.u64	%p2, %rd13, %rd9;
	@%p2 bra 	BB6_24;

	mul.lo.s64 	%rd3, %rd40, %rd9;
	cvt.rn.f64.s32	%fd42, %r50;
	mul.f64 	%fd5, %fd3, %fd42;

BB6_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r52, %r28, %r27, %r29;
	cvt.s64.s32	%rd14, %r52;
	setp.ge.u64	%p3, %rd14, %rd8;
	@%p3 bra 	BB6_23;

	cvt.rn.f64.s32	%fd43, %r51;
	mul.f64 	%fd6, %fd2, %fd43;

BB6_6:
	cvt.rn.f64.s32	%fd44, %r52;
	fma.rn.f64 	%fd45, %fd1, %fd44, %fd6;
	add.f64 	%fd7, %fd45, %fd5;
	abs.f64 	%fd8, %fd7;
	setp.neu.f64	%p4, %fd8, 0d7FF0000000000000;
	mov.f64 	%fd118, %fd7;
	@%p4 bra 	BB6_8;

	mov.f64 	%fd46, 0d0000000000000000;
	mul.rn.f64 	%fd9, %fd7, %fd46;
	mov.f64 	%fd118, %fd9;

BB6_8:
	mov.f64 	%fd10, %fd118;
	add.u64 	%rd15, %SP, 4;
	mul.f64 	%fd47, %fd10, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd47;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r53;
	cvt.rn.f64.s32	%fd48, %r53;
	neg.f64 	%fd49, %fd48;
	mov.f64 	%fd50, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd51, %fd49, %fd50, %fd10;
	mov.f64 	%fd52, 0d3C91A62633145C00;
	fma.rn.f64 	%fd53, %fd49, %fd52, %fd51;
	mov.f64 	%fd54, 0d397B839A252049C0;
	fma.rn.f64 	%fd114, %fd49, %fd54, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd10;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p5, %r35, 1105199104;
	@%p5 bra 	BB6_10;

	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd10;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	}
	// Callseq End 0
	ld.local.u32 	%r53, [%rd16];

BB6_10:
	add.s32 	%r10, %r53, 1;
	and.b32  	%r36, %r10, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p6, %r36, 0;
	selp.f64	%fd55, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p6;
	mul.wide.u32 	%rd19, %r37, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd19, %rd20;
	ld.const.f64 	%fd56, [%rd21+8];
	mul.rn.f64 	%fd14, %fd114, %fd114;
	fma.rn.f64 	%fd57, %fd55, %fd14, %fd56;
	ld.const.f64 	%fd58, [%rd21+16];
	fma.rn.f64 	%fd59, %fd57, %fd14, %fd58;
	ld.const.f64 	%fd60, [%rd21+24];
	fma.rn.f64 	%fd61, %fd59, %fd14, %fd60;
	ld.const.f64 	%fd62, [%rd21+32];
	fma.rn.f64 	%fd63, %fd61, %fd14, %fd62;
	ld.const.f64 	%fd64, [%rd21+40];
	fma.rn.f64 	%fd65, %fd63, %fd14, %fd64;
	ld.const.f64 	%fd66, [%rd21+48];
	fma.rn.f64 	%fd15, %fd65, %fd14, %fd66;
	fma.rn.f64 	%fd115, %fd15, %fd114, %fd114;
	@%p6 bra 	BB6_12;

	mov.f64 	%fd67, 0d3FF0000000000000;
	fma.rn.f64 	%fd115, %fd15, %fd14, %fd67;

BB6_12:
	and.b32  	%r38, %r10, 2;
	setp.eq.s32	%p7, %r38, 0;
	@%p7 bra 	BB6_14;

	mov.f64 	%fd68, 0d0000000000000000;
	mov.f64 	%fd69, 0dBFF0000000000000;
	fma.rn.f64 	%fd115, %fd115, %fd69, %fd68;

BB6_14:
	mov.f64 	%fd117, %fd7;
	@%p4 bra 	BB6_16;

	mov.f64 	%fd70, 0d0000000000000000;
	mul.rn.f64 	%fd117, %fd7, %fd70;

BB6_16:
	add.u64 	%rd22, %SP, 0;
	mul.f64 	%fd71, %fd117, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd71;
	cvta.to.local.u64 	%rd23, %rd22;
	st.local.u32 	[%rd23], %r54;
	cvt.rn.f64.s32	%fd72, %r54;
	neg.f64 	%fd73, %fd72;
	fma.rn.f64 	%fd75, %fd73, %fd50, %fd117;
	fma.rn.f64 	%fd77, %fd73, %fd52, %fd75;
	fma.rn.f64 	%fd119, %fd73, %fd54, %fd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd117;
	}
	and.b32  	%r40, %r39, 2145386496;
	setp.lt.u32	%p9, %r40, 1105199104;
	@%p9 bra 	BB6_18;

	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd117;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd119, [retval0+0];
	}
	// Callseq End 1
	ld.local.u32 	%r54, [%rd23];

BB6_18:
	and.b32  	%r41, %r54, 1;
	shl.b32 	%r42, %r41, 3;
	setp.eq.s32	%p10, %r41, 0;
	selp.f64	%fd79, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	mul.wide.u32 	%rd26, %r42, 8;
	add.s64 	%rd28, %rd26, %rd20;
	ld.const.f64 	%fd80, [%rd28+8];
	mul.rn.f64 	%fd26, %fd119, %fd119;
	fma.rn.f64 	%fd81, %fd79, %fd26, %fd80;
	ld.const.f64 	%fd82, [%rd28+16];
	fma.rn.f64 	%fd83, %fd81, %fd26, %fd82;
	ld.const.f64 	%fd84, [%rd28+24];
	fma.rn.f64 	%fd85, %fd83, %fd26, %fd84;
	ld.const.f64 	%fd86, [%rd28+32];
	fma.rn.f64 	%fd87, %fd85, %fd26, %fd86;
	ld.const.f64 	%fd88, [%rd28+40];
	fma.rn.f64 	%fd89, %fd87, %fd26, %fd88;
	ld.const.f64 	%fd90, [%rd28+48];
	fma.rn.f64 	%fd27, %fd89, %fd26, %fd90;
	fma.rn.f64 	%fd120, %fd27, %fd119, %fd119;
	@%p10 bra 	BB6_20;

	mov.f64 	%fd91, 0d3FF0000000000000;
	fma.rn.f64 	%fd120, %fd27, %fd26, %fd91;

BB6_20:
	and.b32  	%r43, %r54, 2;
	setp.eq.s32	%p11, %r43, 0;
	@%p11 bra 	BB6_22;

	mov.f64 	%fd92, 0d0000000000000000;
	mov.f64 	%fd93, 0dBFF0000000000000;
	fma.rn.f64 	%fd120, %fd120, %fd93, %fd92;

BB6_22:
	div.rn.f64 	%fd94, %fd115, %fd4;
	cvt.u64.u32	%rd29, %r51;
	add.s64 	%rd30, %rd29, %rd3;
	mul.lo.s64 	%rd31, %rd30, %rd11;
	cvt.u64.u32	%rd32, %r52;
	add.s64 	%rd33, %rd32, %rd31;
	cvt.s64.s32 	%rd34, %rd33;
	shl.b64 	%rd35, %rd34, 4;
	add.s64 	%rd36, %rd5, %rd35;
	ld.v2.f64 	{%fd95, %fd96}, [%rd36];
	mul.f64 	%fd98, %fd95, %fd94;
	div.rn.f64 	%fd99, %fd120, %fd4;
	mul.f64 	%fd101, %fd96, %fd99;
	mul.f64 	%fd102, %fd96, %fd94;
	add.s64 	%rd37, %rd6, %rd35;
	sub.f64 	%fd103, %fd98, %fd101;
	fma.rn.f64 	%fd104, %fd95, %fd99, %fd102;
	st.v2.f64 	[%rd36], {%fd103, %fd104};
	ld.v2.f64 	{%fd105, %fd106}, [%rd37];
	mul.f64 	%fd108, %fd105, %fd94;
	mul.f64 	%fd110, %fd106, %fd99;
	mul.f64 	%fd111, %fd106, %fd94;
	mov.u32 	%r45, %nctaid.x;
	mad.lo.s32 	%r52, %r45, %r28, %r52;
	cvt.s64.s32	%rd38, %r52;
	setp.lt.u64	%p12, %rd38, %rd8;
	sub.f64 	%fd112, %fd108, %fd110;
	fma.rn.f64 	%fd113, %fd105, %fd99, %fd111;
	st.v2.f64 	[%rd37], {%fd112, %fd113};
	@%p12 bra 	BB6_6;

BB6_23:
	mov.u32 	%r46, %nctaid.y;
	mad.lo.s32 	%r51, %r46, %r21, %r51;
	cvt.s64.s32	%rd39, %r51;
	setp.lt.u64	%p13, %rd39, %rd9;
	@%p13 bra 	BB6_4;

BB6_24:
	mov.u32 	%r48, %nctaid.z;
	mad.lo.s32 	%r50, %r48, %r17, %r50;
	cvt.s64.s32	%rd40, %r50;
	setp.lt.u64	%p14, %rd40, %rd10;
	@%p14 bra 	BB6_2;

BB6_25:
	ret;
}

.visible .func _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm(
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_0,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_1,
	.param .b32 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_2,
	.param .b32 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_3,
	.param .b32 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_4,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_5,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_6,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_7,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_8,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_9,
	.param .b64 _Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_10
)
{
	.local .align 4 .b8 	__local_depot7[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .s32 	%r<219>;
	.reg .f32 	%f<133>;
	.reg .s64 	%rd<54>;


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd18, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_0];
	ld.param.u64 	%rd19, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_1];
	ld.param.f32 	%f44, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_2];
	ld.param.f32 	%f45, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_3];
	ld.param.f32 	%f46, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_4];
	ld.param.u64 	%rd20, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_5];
	ld.param.u64 	%rd21, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_6];
	ld.param.u64 	%rd22, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_7];
	ld.param.u64 	%rd23, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_8];
	ld.param.u64 	%rd24, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_9];
	ld.param.u64 	%rd25, [_Z14kernel_fdshiftI6float2fEvPT_S2_T0_S3_S3_mmmmmm_param_10];
	mov.u32 	%r83, %ntid.z;
	mov.u32 	%r84, %ctaid.z;
	mov.u32 	%r85, %tid.z;
	mad.lo.s32 	%r196, %r83, %r84, %r85;
	cvt.s64.s32	%rd49, %r196;
	setp.ge.u64	%p1, %rd49, %rd23;
	@%p1 bra 	BB7_53;

	cvt.rn.f32.u64	%f47, %rd20;
	mul.f32 	%f48, %f44, 0f40C90FDB;
	div.rn.f32 	%f1, %f48, %f47;
	cvt.rn.f32.u64	%f49, %rd22;
	mul.f32 	%f50, %f45, 0f40C90FDB;
	div.rn.f32 	%f2, %f50, %f49;
	cvt.rn.f32.u64	%f51, %rd23;
	mul.f32 	%f52, %f46, 0f40C90FDB;
	div.rn.f32 	%f3, %f52, %f51;

BB7_2:
	mov.u32 	%r86, %ctaid.y;
	mov.u32 	%r87, %ntid.y;
	mov.u32 	%r88, %tid.y;
	mad.lo.s32 	%r197, %r87, %r86, %r88;
	cvt.s64.s32	%rd26, %r197;
	setp.ge.u64	%p2, %rd26, %rd22;
	@%p2 bra 	BB7_52;

	mul.lo.s64 	%rd3, %rd49, %rd22;
	cvt.rn.f32.s32	%f53, %r196;
	mul.f32 	%f4, %f3, %f53;

BB7_4:
	mov.u32 	%r93, %ctaid.x;
	mov.u32 	%r94, %ntid.x;
	mov.u32 	%r95, %tid.x;
	mad.lo.s32 	%r198, %r94, %r93, %r95;
	cvt.s64.s32	%rd27, %r198;
	setp.ge.u64	%p3, %rd27, %rd21;
	@%p3 bra 	BB7_51;

	cvt.u64.u32	%rd28, %r197;
	add.s64 	%rd29, %rd28, %rd3;
	cvt.s64.s32 	%rd4, %rd29;
	cvt.rn.f32.s32	%f54, %r197;
	mul.f32 	%f5, %f2, %f54;
	cvt.rn.f32.u64	%f6, %rd25;

BB7_6:
	cvt.rn.f32.s32	%f55, %r198;
	fma.rn.f32 	%f56, %f1, %f55, %f5;
	add.f32 	%f7, %f56, %f4;
	abs.f32 	%f8, %f7;
	setp.neu.f32	%p4, %f8, 0f7F800000;
	mov.f32 	%f128, %f7;
	@%p4 bra 	BB7_8;

	mov.f32 	%f57, 0f00000000;
	mul.rn.f32 	%f9, %f7, %f57;
	mov.f32 	%f128, %f9;

BB7_8:
	mov.f32 	%f10, %f128;
	mul.f32 	%f58, %f10, 0f3F22F983;
	cvt.rni.s32.f32	%r208, %f58;
	cvt.rn.f32.s32	%f59, %r208;
	neg.f32 	%f60, %f59;
	mov.f32 	%f61, 0f3FC90FDA;
	fma.rn.f32 	%f62, %f60, %f61, %f10;
	mov.f32 	%f63, 0f33A22168;
	fma.rn.f32 	%f64, %f60, %f63, %f62;
	mov.f32 	%f65, 0f27C234C5;
	fma.rn.f32 	%f122, %f60, %f65, %f64;
	abs.f32 	%f66, %f10;
	setp.leu.f32	%p5, %f66, 0f47CE4780;
	@%p5 bra 	BB7_18;

	add.u64 	%rd31, %SP, 0;
	mov.b32 	 %r8, %f10;
	shr.u32 	%r9, %r8, 23;
	bfe.u32 	%r102, %r8, 23, 8;
	add.s32 	%r103, %r102, -128;
	shl.b32 	%r104, %r8, 8;
	or.b32  	%r10, %r104, -2147483648;
	shr.u32 	%r11, %r103, 5;
	cvta.to.local.u64 	%rd51, %rd31;
	mov.u32 	%r200, 0;
	mov.u32 	%r199, %r200;
	mov.u64 	%rd50, __cudart_i2opi_f;

BB7_10:
	.pragma "nounroll";
	ld.const.u32 	%r107, [%rd50];
	// inline asm
	{
	mad.lo.cc.u32   %r105, %r107, %r10, %r200;
	madc.hi.u32     %r106, %r107, %r10,  0;
	}
	// inline asm
	st.local.u32 	[%rd51], %r105;
	add.s64 	%rd51, %rd51, 4;
	add.s64 	%rd50, %rd50, 4;
	add.s32 	%r199, %r199, 1;
	setp.ne.s32	%p6, %r199, 6;
	mov.u32 	%r200, %r106;
	@%p6 bra 	BB7_10;

	and.b32  	%r16, %r8, -2147483648;
	cvta.to.local.u64 	%rd33, %rd31;
	st.local.u32 	[%rd33+24], %r106;
	mov.u32 	%r110, 6;
	sub.s32 	%r111, %r110, %r11;
	mul.wide.s32 	%rd34, %r111, 4;
	add.s64 	%rd10, %rd33, %rd34;
	ld.local.u32 	%r201, [%rd10];
	ld.local.u32 	%r202, [%rd10+-4];
	and.b32  	%r19, %r9, 31;
	setp.eq.s32	%p7, %r19, 0;
	@%p7 bra 	BB7_13;

	mov.u32 	%r112, 32;
	sub.s32 	%r113, %r112, %r19;
	shr.u32 	%r114, %r202, %r113;
	shl.b32 	%r115, %r201, %r19;
	add.s32 	%r201, %r114, %r115;
	ld.local.u32 	%r116, [%rd10+-8];
	shr.u32 	%r117, %r116, %r113;
	shl.b32 	%r118, %r202, %r19;
	add.s32 	%r202, %r117, %r118;

BB7_13:
	shr.u32 	%r119, %r202, 30;
	shl.b32 	%r120, %r201, 2;
	add.s32 	%r203, %r119, %r120;
	shl.b32 	%r25, %r202, 2;
	shr.u32 	%r121, %r203, 31;
	shr.u32 	%r122, %r201, 30;
	add.s32 	%r26, %r121, %r122;
	setp.eq.s32	%p8, %r121, 0;
	mov.u32 	%r204, %r16;
	mov.u32 	%r205, %r25;
	@%p8 bra 	BB7_15;

	not.b32 	%r123, %r203;
	neg.s32 	%r27, %r25;
	setp.eq.s32	%p9, %r25, 0;
	selp.u32	%r124, 1, 0, %p9;
	add.s32 	%r203, %r124, %r123;
	xor.b32  	%r29, %r16, -2147483648;
	mov.u32 	%r204, %r29;
	mov.u32 	%r205, %r27;

BB7_15:
	mov.u32 	%r31, %r204;
	neg.s32 	%r125, %r26;
	setp.eq.s32	%p10, %r16, 0;
	selp.b32	%r208, %r26, %r125, %p10;
	clz.b32 	%r207, %r203;
	setp.eq.s32	%p11, %r207, 0;
	shl.b32 	%r126, %r203, %r207;
	mov.u32 	%r127, 32;
	sub.s32 	%r128, %r127, %r207;
	shr.u32 	%r129, %r205, %r128;
	add.s32 	%r130, %r129, %r126;
	selp.b32	%r35, %r203, %r130, %p11;
	mov.u32 	%r131, -921707870;
	mul.hi.u32 	%r206, %r35, %r131;
	setp.lt.s32	%p12, %r206, 1;
	@%p12 bra 	BB7_17;

	mul.lo.s32 	%r132, %r35, -921707870;
	shr.u32 	%r133, %r132, 31;
	shl.b32 	%r134, %r206, 1;
	add.s32 	%r206, %r133, %r134;
	add.s32 	%r207, %r207, 1;

BB7_17:
	mov.u32 	%r135, 126;
	sub.s32 	%r136, %r135, %r207;
	shl.b32 	%r137, %r136, 23;
	add.s32 	%r138, %r206, 1;
	shr.u32 	%r139, %r138, 7;
	add.s32 	%r140, %r139, 1;
	shr.u32 	%r141, %r140, 1;
	add.s32 	%r142, %r141, %r137;
	or.b32  	%r143, %r142, %r31;
	mov.b32 	 %f122, %r143;

BB7_18:
	mul.rn.f32 	%f14, %f122, %f122;
	add.s32 	%r42, %r208, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32	%p13, %r43, 0;
	@%p13 bra 	BB7_20;

	mov.f32 	%f67, 0fBAB6061A;
	mov.f32 	%f68, 0f37CCF5CE;
	fma.rn.f32 	%f123, %f68, %f14, %f67;
	bra.uni 	BB7_21;

BB7_20:
	mov.f32 	%f69, 0f3C08839E;
	mov.f32 	%f70, 0fB94CA1F9;
	fma.rn.f32 	%f123, %f70, %f14, %f69;

BB7_21:
	@%p13 bra 	BB7_23;

	mov.f32 	%f71, 0f3D2AAAA5;
	fma.rn.f32 	%f72, %f123, %f14, %f71;
	mov.f32 	%f73, 0fBF000000;
	fma.rn.f32 	%f124, %f72, %f14, %f73;
	bra.uni 	BB7_24;

BB7_23:
	mov.f32 	%f74, 0fBE2AAAA3;
	fma.rn.f32 	%f75, %f123, %f14, %f74;
	mov.f32 	%f76, 0f00000000;
	fma.rn.f32 	%f124, %f75, %f14, %f76;

BB7_24:
	fma.rn.f32 	%f125, %f124, %f122, %f122;
	@%p13 bra 	BB7_26;

	mov.f32 	%f77, 0f3F800000;
	fma.rn.f32 	%f125, %f124, %f14, %f77;

BB7_26:
	and.b32  	%r144, %r42, 2;
	setp.eq.s32	%p16, %r144, 0;
	@%p16 bra 	BB7_28;

	mov.f32 	%f78, 0f00000000;
	mov.f32 	%f79, 0fBF800000;
	fma.rn.f32 	%f125, %f125, %f79, %f78;

BB7_28:
	mov.f32 	%f127, %f7;
	@%p4 bra 	BB7_30;

	mov.f32 	%f80, 0f00000000;
	mul.rn.f32 	%f127, %f7, %f80;

BB7_30:
	mul.f32 	%f81, %f127, 0f3F22F983;
	cvt.rni.s32.f32	%r218, %f81;
	cvt.rn.f32.s32	%f82, %r218;
	neg.f32 	%f83, %f82;
	fma.rn.f32 	%f85, %f83, %f61, %f127;
	fma.rn.f32 	%f87, %f83, %f63, %f85;
	fma.rn.f32 	%f129, %f83, %f65, %f87;
	abs.f32 	%f89, %f127;
	setp.leu.f32	%p18, %f89, 0f47CE4780;
	@%p18 bra 	BB7_40;

	add.u64 	%rd36, %SP, 0;
	mov.b32 	 %r45, %f127;
	shr.u32 	%r46, %r45, 23;
	bfe.u32 	%r147, %r45, 23, 8;
	add.s32 	%r148, %r147, -128;
	shl.b32 	%r149, %r45, 8;
	or.b32  	%r47, %r149, -2147483648;
	shr.u32 	%r48, %r148, 5;
	cvta.to.local.u64 	%rd53, %rd36;
	mov.u32 	%r210, 0;
	mov.u32 	%r209, %r210;
	mov.u64 	%rd52, __cudart_i2opi_f;

BB7_32:
	.pragma "nounroll";
	ld.const.u32 	%r152, [%rd52];
	// inline asm
	{
	mad.lo.cc.u32   %r150, %r152, %r47, %r210;
	madc.hi.u32     %r151, %r152, %r47,  0;
	}
	// inline asm
	st.local.u32 	[%rd53], %r150;
	add.s64 	%rd53, %rd53, 4;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r209, %r209, 1;
	setp.ne.s32	%p19, %r209, 6;
	mov.u32 	%r210, %r151;
	@%p19 bra 	BB7_32;

	and.b32  	%r53, %r45, -2147483648;
	cvta.to.local.u64 	%rd38, %rd36;
	st.local.u32 	[%rd38+24], %r151;
	mov.u32 	%r155, 6;
	sub.s32 	%r156, %r155, %r48;
	mul.wide.s32 	%rd39, %r156, 4;
	add.s64 	%rd16, %rd38, %rd39;
	ld.local.u32 	%r211, [%rd16];
	ld.local.u32 	%r212, [%rd16+-4];
	and.b32  	%r56, %r46, 31;
	setp.eq.s32	%p20, %r56, 0;
	@%p20 bra 	BB7_35;

	mov.u32 	%r157, 32;
	sub.s32 	%r158, %r157, %r56;
	shr.u32 	%r159, %r212, %r158;
	shl.b32 	%r160, %r211, %r56;
	add.s32 	%r211, %r159, %r160;
	ld.local.u32 	%r161, [%rd16+-8];
	shr.u32 	%r162, %r161, %r158;
	shl.b32 	%r163, %r212, %r56;
	add.s32 	%r212, %r162, %r163;

BB7_35:
	shr.u32 	%r164, %r212, 30;
	shl.b32 	%r165, %r211, 2;
	add.s32 	%r213, %r164, %r165;
	shl.b32 	%r62, %r212, 2;
	shr.u32 	%r166, %r213, 31;
	shr.u32 	%r167, %r211, 30;
	add.s32 	%r63, %r166, %r167;
	setp.eq.s32	%p21, %r166, 0;
	mov.u32 	%r214, %r53;
	mov.u32 	%r215, %r62;
	@%p21 bra 	BB7_37;

	not.b32 	%r168, %r213;
	neg.s32 	%r64, %r62;
	setp.eq.s32	%p22, %r62, 0;
	selp.u32	%r169, 1, 0, %p22;
	add.s32 	%r213, %r169, %r168;
	xor.b32  	%r66, %r53, -2147483648;
	mov.u32 	%r214, %r66;
	mov.u32 	%r215, %r64;

BB7_37:
	mov.u32 	%r68, %r214;
	neg.s32 	%r170, %r63;
	setp.eq.s32	%p23, %r53, 0;
	selp.b32	%r218, %r63, %r170, %p23;
	clz.b32 	%r217, %r213;
	setp.eq.s32	%p24, %r217, 0;
	shl.b32 	%r171, %r213, %r217;
	mov.u32 	%r172, 32;
	sub.s32 	%r173, %r172, %r217;
	shr.u32 	%r174, %r215, %r173;
	add.s32 	%r175, %r174, %r171;
	selp.b32	%r72, %r213, %r175, %p24;
	mov.u32 	%r176, -921707870;
	mul.hi.u32 	%r216, %r72, %r176;
	setp.lt.s32	%p25, %r216, 1;
	@%p25 bra 	BB7_39;

	mul.lo.s32 	%r177, %r72, -921707870;
	shr.u32 	%r178, %r177, 31;
	shl.b32 	%r179, %r216, 1;
	add.s32 	%r216, %r178, %r179;
	add.s32 	%r217, %r217, 1;

BB7_39:
	mov.u32 	%r180, 126;
	sub.s32 	%r181, %r180, %r217;
	shl.b32 	%r182, %r181, 23;
	add.s32 	%r183, %r216, 1;
	shr.u32 	%r184, %r183, 7;
	add.s32 	%r185, %r184, 1;
	shr.u32 	%r186, %r185, 1;
	add.s32 	%r187, %r186, %r182;
	or.b32  	%r188, %r187, %r68;
	mov.b32 	 %f129, %r188;

BB7_40:
	div.rn.f32 	%f31, %f125, %f6;
	mul.rn.f32 	%f32, %f129, %f129;
	and.b32  	%r79, %r218, 1;
	setp.eq.s32	%p26, %r79, 0;
	@%p26 bra 	BB7_42;

	mov.f32 	%f90, 0fBAB6061A;
	mov.f32 	%f91, 0f37CCF5CE;
	fma.rn.f32 	%f130, %f91, %f32, %f90;
	bra.uni 	BB7_43;

BB7_42:
	mov.f32 	%f92, 0f3C08839E;
	mov.f32 	%f93, 0fB94CA1F9;
	fma.rn.f32 	%f130, %f93, %f32, %f92;

BB7_43:
	@%p26 bra 	BB7_45;

	mov.f32 	%f94, 0f3D2AAAA5;
	fma.rn.f32 	%f95, %f130, %f32, %f94;
	mov.f32 	%f96, 0fBF000000;
	fma.rn.f32 	%f131, %f95, %f32, %f96;
	bra.uni 	BB7_46;

BB7_45:
	mov.f32 	%f97, 0fBE2AAAA3;
	fma.rn.f32 	%f98, %f130, %f32, %f97;
	mov.f32 	%f99, 0f00000000;
	fma.rn.f32 	%f131, %f98, %f32, %f99;

BB7_46:
	fma.rn.f32 	%f132, %f131, %f129, %f129;
	@%p26 bra 	BB7_48;

	mov.f32 	%f100, 0f3F800000;
	fma.rn.f32 	%f132, %f131, %f32, %f100;

BB7_48:
	and.b32  	%r189, %r218, 2;
	setp.eq.s32	%p29, %r189, 0;
	@%p29 bra 	BB7_50;

	mov.f32 	%f101, 0f00000000;
	mov.f32 	%f102, 0fBF800000;
	fma.rn.f32 	%f132, %f132, %f102, %f101;

BB7_50:
	mul.lo.s64 	%rd40, %rd4, %rd24;
	cvt.u64.u32	%rd41, %r198;
	add.s64 	%rd42, %rd41, %rd40;
	cvt.s64.s32 	%rd43, %rd42;
	shl.b64 	%rd44, %rd43, 3;
	add.s64 	%rd45, %rd18, %rd44;
	ld.v2.f32 	{%f103, %f104}, [%rd45];
	mul.f32 	%f106, %f103, %f31;
	div.rn.f32 	%f107, %f132, %f6;
	mul.f32 	%f109, %f104, %f107;
	mul.f32 	%f110, %f104, %f31;
	add.s64 	%rd46, %rd19, %rd44;
	fma.rn.f32 	%f111, %f103, %f107, %f110;
	sub.f32 	%f112, %f106, %f109;
	st.v2.f32 	[%rd45], {%f112, %f111};
	ld.v2.f32 	{%f113, %f114}, [%rd46];
	mul.f32 	%f116, %f113, %f31;
	mul.f32 	%f118, %f114, %f107;
	mul.f32 	%f119, %f114, %f31;
	mov.u32 	%r191, %nctaid.x;
	mad.lo.s32 	%r198, %r191, %r94, %r198;
	cvt.s64.s32	%rd47, %r198;
	setp.lt.u64	%p30, %rd47, %rd21;
	fma.rn.f32 	%f120, %f113, %f107, %f119;
	sub.f32 	%f121, %f116, %f118;
	st.v2.f32 	[%rd46], {%f121, %f120};
	@%p30 bra 	BB7_6;

BB7_51:
	mov.u32 	%r192, %nctaid.y;
	mad.lo.s32 	%r197, %r192, %r87, %r197;
	cvt.s64.s32	%rd48, %r197;
	setp.lt.u64	%p31, %rd48, %rd22;
	@%p31 bra 	BB7_4;

BB7_52:
	mov.u32 	%r194, %nctaid.z;
	mad.lo.s32 	%r196, %r194, %r83, %r196;
	cvt.s64.s32	%rd49, %r196;
	setp.lt.u64	%p32, %rd49, %rd23;
	@%p32 bra 	BB7_2;

BB7_53:
	ret;
}

.visible .entry kernel_conv_components_double(
	.param .u64 kernel_conv_components_double_param_0,
	.param .u64 kernel_conv_components_double_param_1,
	.param .u64 kernel_conv_components_double_param_2,
	.param .u64 kernel_conv_components_double_param_3,
	.param .u64 kernel_conv_components_double_param_4,
	.param .u64 kernel_conv_components_double_param_5,
	.param .u64 kernel_conv_components_double_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .s32 	%r<38>;
	.reg .s64 	%rd<33>;
	.reg .f64 	%fd<8>;


	ld.param.u64 	%rd9, [kernel_conv_components_double_param_0];
	ld.param.u64 	%rd10, [kernel_conv_components_double_param_1];
	ld.param.u64 	%rd11, [kernel_conv_components_double_param_2];
	ld.param.u64 	%rd12, [kernel_conv_components_double_param_3];
	ld.param.u64 	%rd13, [kernel_conv_components_double_param_4];
	ld.param.u64 	%rd14, [kernel_conv_components_double_param_5];
	ld.param.u64 	%rd15, [kernel_conv_components_double_param_6];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r35, %r11, %r12, %r13;
	cvt.s64.s32	%rd32, %r35;
	setp.ge.u64	%p1, %rd32, %rd14;
	@%p1 bra 	BB8_11;

	cvta.to.global.u64 	%rd2, %rd11;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %nctaid.x;
	mul.lo.s32 	%r2, %r15, %r14;
	cvta.to.global.u64 	%rd21, %rd9;
	cvta.to.global.u64 	%rd26, %rd10;

BB8_2:
	mov.u32 	%r16, %ctaid.y;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %tid.y;
	mad.lo.s32 	%r36, %r17, %r16, %r18;
	cvt.s64.s32	%rd16, %r36;
	setp.ge.u64	%p2, %rd16, %rd13;
	@%p2 bra 	BB8_10;

	mul.lo.s64 	%rd4, %rd32, %rd13;

BB8_4:
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r37, %r14, %r23, %r25;
	cvt.s64.s32	%rd17, %r37;
	setp.ge.u64	%p3, %rd17, %rd12;
	@%p3 bra 	BB8_9;

	cvt.u64.u32	%rd18, %r36;
	add.s64 	%rd19, %rd18, %rd4;
	cvt.s64.s32 	%rd20, %rd19;
	mul.lo.s64 	%rd5, %rd20, %rd15;

BB8_6:
	cvt.u64.u32	%rd22, %r37;
	add.s64 	%rd23, %rd22, %rd5;
	cvt.s64.s32 	%rd6, %rd23;
	shl.b64 	%rd24, %rd6, 3;
	add.s64 	%rd7, %rd21, %rd24;
	ld.global.f64 	%fd7, [%rd7];
	abs.f64 	%fd2, %fd7;
	setp.le.f64	%p4, %fd2, 0d7FF0000000000000;
	@%p4 bra 	BB8_8;

	mov.u64 	%rd25, 0;
	st.global.u64 	[%rd7], %rd25;
	mov.f64 	%fd7, 0d0000000000000000;

BB8_8:
	selp.u32	%r30, 1, 0, %p4;
	cvt.rn.f64.s32	%fd5, %r30;
	add.s64 	%rd28, %rd2, %rd24;
	st.global.f64 	[%rd28], %fd5;
	add.s64 	%rd29, %rd26, %rd24;
	mul.f64 	%fd6, %fd7, %fd7;
	st.global.f64 	[%rd29], %fd6;
	add.s32 	%r37, %r2, %r37;
	cvt.s64.s32	%rd30, %r37;
	setp.lt.u64	%p6, %rd30, %rd12;
	@%p6 bra 	BB8_6;

BB8_9:
	mov.u32 	%r31, %nctaid.y;
	mad.lo.s32 	%r36, %r31, %r17, %r36;
	cvt.s64.s32	%rd31, %r36;
	setp.lt.u64	%p7, %rd31, %rd13;
	@%p7 bra 	BB8_4;

BB8_10:
	mov.u32 	%r33, %nctaid.z;
	mad.lo.s32 	%r35, %r33, %r11, %r35;
	cvt.s64.s32	%rd32, %r35;
	setp.lt.u64	%p8, %rd32, %rd14;
	@%p8 bra 	BB8_2;

BB8_11:
	ret;
}

.visible .entry kernel_conv_components_float(
	.param .u64 kernel_conv_components_float_param_0,
	.param .u64 kernel_conv_components_float_param_1,
	.param .u64 kernel_conv_components_float_param_2,
	.param .u64 kernel_conv_components_float_param_3,
	.param .u64 kernel_conv_components_float_param_4,
	.param .u64 kernel_conv_components_float_param_5,
	.param .u64 kernel_conv_components_float_param_6
)
{
	.reg .pred 	%p<9>;
	.reg .s32 	%r<39>;
	.reg .f32 	%f<8>;
	.reg .s64 	%rd<32>;


	ld.param.u64 	%rd9, [kernel_conv_components_float_param_0];
	ld.param.u64 	%rd10, [kernel_conv_components_float_param_1];
	ld.param.u64 	%rd11, [kernel_conv_components_float_param_2];
	ld.param.u64 	%rd12, [kernel_conv_components_float_param_3];
	ld.param.u64 	%rd13, [kernel_conv_components_float_param_4];
	ld.param.u64 	%rd14, [kernel_conv_components_float_param_5];
	ld.param.u64 	%rd15, [kernel_conv_components_float_param_6];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r36, %r11, %r12, %r13;
	cvt.s64.s32	%rd31, %r36;
	setp.ge.u64	%p1, %rd31, %rd14;
	@%p1 bra 	BB9_11;

	cvta.to.global.u64 	%rd2, %rd11;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %nctaid.x;
	mul.lo.s32 	%r2, %r15, %r14;
	cvta.to.global.u64 	%rd23, %rd9;
	cvta.to.global.u64 	%rd27, %rd10;

BB9_2:
	mov.u32 	%r16, %ctaid.y;
	mov.u32 	%r17, %ntid.y;
	mov.u32 	%r18, %tid.y;
	mad.lo.s32 	%r37, %r17, %r16, %r18;
	cvt.s64.s32	%rd16, %r37;
	setp.ge.u64	%p2, %rd16, %rd13;
	@%p2 bra 	BB9_10;

	mul.lo.s64 	%rd4, %rd31, %rd13;

BB9_4:
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r38, %r14, %r23, %r25;
	cvt.s64.s32	%rd17, %r38;
	setp.ge.u64	%p3, %rd17, %rd12;
	@%p3 bra 	BB9_9;

	cvt.u64.u32	%rd18, %r37;
	add.s64 	%rd19, %rd18, %rd4;
	cvt.s64.s32 	%rd20, %rd19;
	mul.lo.s64 	%rd5, %rd20, %rd15;

BB9_6:
	cvt.u64.u32	%rd21, %r38;
	add.s64 	%rd22, %rd21, %rd5;
	cvt.s64.s32 	%rd6, %rd22;
	shl.b64 	%rd24, %rd6, 2;
	add.s64 	%rd7, %rd23, %rd24;
	ld.global.f32 	%f7, [%rd7];
	abs.f32 	%f2, %f7;
	setp.le.f32	%p4, %f2, 0f7F800000;
	@%p4 bra 	BB9_8;

	mov.u32 	%r30, 0;
	st.global.u32 	[%rd7], %r30;
	mov.f32 	%f7, 0f00000000;

BB9_8:
	selp.u32	%r31, 1, 0, %p4;
	cvt.rn.f32.s32	%f5, %r31;
	add.s64 	%rd26, %rd2, %rd24;
	st.global.f32 	[%rd26], %f5;
	add.s64 	%rd28, %rd27, %rd24;
	mul.f32 	%f6, %f7, %f7;
	st.global.f32 	[%rd28], %f6;
	add.s32 	%r38, %r2, %r38;
	cvt.s64.s32	%rd29, %r38;
	setp.lt.u64	%p6, %rd29, %rd12;
	@%p6 bra 	BB9_6;

BB9_9:
	mov.u32 	%r32, %nctaid.y;
	mad.lo.s32 	%r37, %r32, %r17, %r37;
	cvt.s64.s32	%rd30, %r37;
	setp.lt.u64	%p7, %rd30, %rd13;
	@%p7 bra 	BB9_4;

BB9_10:
	mov.u32 	%r34, %nctaid.z;
	mad.lo.s32 	%r36, %r34, %r11, %r36;
	cvt.s64.s32	%rd31, %r36;
	setp.lt.u64	%p8, %rd31, %rd14;
	@%p8 bra 	BB9_2;

BB9_11:
	ret;
}

.visible .entry kernel_calcNumDenom_intensity_double(
	.param .u64 kernel_calcNumDenom_intensity_double_param_0,
	.param .u64 kernel_calcNumDenom_intensity_double_param_1,
	.param .u64 kernel_calcNumDenom_intensity_double_param_2,
	.param .u64 kernel_calcNumDenom_intensity_double_param_3,
	.param .u64 kernel_calcNumDenom_intensity_double_param_4,
	.param .u64 kernel_calcNumDenom_intensity_double_param_5,
	.param .u64 kernel_calcNumDenom_intensity_double_param_6,
	.param .u64 kernel_calcNumDenom_intensity_double_param_7,
	.param .u64 kernel_calcNumDenom_intensity_double_param_8,
	.param .u64 kernel_calcNumDenom_intensity_double_param_9,
	.param .u64 kernel_calcNumDenom_intensity_double_param_10,
	.param .u64 kernel_calcNumDenom_intensity_double_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<41>;
	.reg .s64 	%rd<46>;
	.reg .f64 	%fd<49>;


	ld.param.u64 	%rd11, [kernel_calcNumDenom_intensity_double_param_0];
	ld.param.u64 	%rd12, [kernel_calcNumDenom_intensity_double_param_1];
	ld.param.u64 	%rd13, [kernel_calcNumDenom_intensity_double_param_2];
	ld.param.u64 	%rd14, [kernel_calcNumDenom_intensity_double_param_3];
	ld.param.u64 	%rd15, [kernel_calcNumDenom_intensity_double_param_4];
	ld.param.u64 	%rd16, [kernel_calcNumDenom_intensity_double_param_5];
	ld.param.u64 	%rd17, [kernel_calcNumDenom_intensity_double_param_6];
	ld.param.u64 	%rd18, [kernel_calcNumDenom_intensity_double_param_7];
	ld.param.u64 	%rd19, [kernel_calcNumDenom_intensity_double_param_8];
	ld.param.u64 	%rd20, [kernel_calcNumDenom_intensity_double_param_9];
	ld.param.u64 	%rd21, [kernel_calcNumDenom_intensity_double_param_10];
	ld.param.u64 	%rd22, [kernel_calcNumDenom_intensity_double_param_11];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r38, %r11, %r12, %r13;
	cvt.s64.s32	%rd45, %r38;
	setp.ge.u64	%p1, %rd45, %rd21;
	@%p1 bra 	BB10_9;

	cvta.to.global.u64 	%rd2, %rd18;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd14;
	cvta.to.global.u64 	%rd5, %rd16;
	cvta.to.global.u64 	%rd6, %rd12;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %nctaid.x;
	mul.lo.s32 	%r1, %r16, %r15;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd15;
	cvta.to.global.u64 	%rd30, %rd11;

BB10_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r39, %r21, %r20, %r22;
	cvt.s64.s32	%rd23, %r39;
	setp.ge.u64	%p2, %rd23, %rd20;
	@%p2 bra 	BB10_8;

	mul.lo.s64 	%rd8, %rd45, %rd20;

BB10_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r40, %r15, %r27, %r29;
	cvt.s64.s32	%rd24, %r40;
	setp.ge.u64	%p3, %rd24, %rd19;
	@%p3 bra 	BB10_7;

	cvt.u64.u32	%rd25, %r39;
	add.s64 	%rd26, %rd25, %rd8;
	cvt.s64.s32 	%rd27, %rd26;
	mul.lo.s64 	%rd9, %rd27, %rd22;

BB10_6:
	cvt.u64.u32	%rd31, %r40;
	add.s64 	%rd32, %rd31, %rd9;
	cvt.s64.s32 	%rd33, %rd32;
	shl.b64 	%rd34, %rd33, 4;
	add.s64 	%rd35, %rd6, %rd34;
	ld.global.v2.f64 	{%fd1, %fd2}, [%rd35];
	add.s64 	%rd36, %rd5, %rd34;
	ld.global.v2.f64 	{%fd3, %fd4}, [%rd36];
	mul.f64 	%fd7, %fd4, %fd2;
	fma.rn.f64 	%fd10, %fd1, %fd3, %fd7;
	mul.f64 	%fd11, %fd1, %fd4;
	mul.f64 	%fd12, %fd3, %fd2;
	sub.f64 	%fd13, %fd11, %fd12;
	add.s64 	%rd37, %rd28, %rd34;
	ld.global.v2.f64 	{%fd14, %fd15}, [%rd37];
	add.s64 	%rd38, %rd29, %rd34;
	ld.global.v2.f64 	{%fd16, %fd17}, [%rd38];
	mul.f64 	%fd20, %fd17, %fd15;
	fma.rn.f64 	%fd23, %fd14, %fd16, %fd20;
	mul.f64 	%fd24, %fd14, %fd17;
	mul.f64 	%fd25, %fd16, %fd15;
	sub.f64 	%fd26, %fd24, %fd25;
	add.s64 	%rd39, %rd30, %rd34;
	ld.global.v2.f64 	{%fd27, %fd28}, [%rd39];
	add.s64 	%rd40, %rd4, %rd34;
	ld.global.v2.f64 	{%fd29, %fd30}, [%rd40];
	mul.f64 	%fd33, %fd30, %fd28;
	fma.rn.f64 	%fd36, %fd27, %fd29, %fd33;
	mul.f64 	%fd37, %fd27, %fd30;
	mul.f64 	%fd38, %fd29, %fd28;
	sub.f64 	%fd39, %fd37, %fd38;
	add.f64 	%fd40, %fd36, %fd36;
	mul.f64 	%fd41, %fd39, 0d0000000000000000;
	sub.f64 	%fd42, %fd40, %fd41;
	mul.f64 	%fd43, %fd36, 0d0000000000000000;
	fma.rn.f64 	%fd44, %fd39, 0d4000000000000000, %fd43;
	add.s64 	%rd41, %rd3, %rd34;
	add.f64 	%fd45, %fd13, %fd26;
	sub.f64 	%fd46, %fd45, %fd44;
	add.f64 	%fd47, %fd10, %fd23;
	sub.f64 	%fd48, %fd47, %fd42;
	st.global.v2.f64 	[%rd41], {%fd48, %fd46};
	add.s64 	%rd42, %rd2, %rd34;
	st.global.v2.f64 	[%rd42], {%fd47, %fd45};
	add.s32 	%r40, %r1, %r40;
	cvt.s64.s32	%rd43, %r40;
	setp.lt.u64	%p4, %rd43, %rd19;
	@%p4 bra 	BB10_6;

BB10_7:
	mov.u32 	%r34, %nctaid.y;
	mad.lo.s32 	%r39, %r34, %r21, %r39;
	cvt.s64.s32	%rd44, %r39;
	setp.lt.u64	%p5, %rd44, %rd20;
	@%p5 bra 	BB10_4;

BB10_8:
	mov.u32 	%r36, %nctaid.z;
	mad.lo.s32 	%r38, %r36, %r11, %r38;
	cvt.s64.s32	%rd45, %r38;
	setp.lt.u64	%p6, %rd45, %rd21;
	@%p6 bra 	BB10_2;

BB10_9:
	ret;
}

.visible .entry kernel_calcNumDenom_intensity_float(
	.param .u64 kernel_calcNumDenom_intensity_float_param_0,
	.param .u64 kernel_calcNumDenom_intensity_float_param_1,
	.param .u64 kernel_calcNumDenom_intensity_float_param_2,
	.param .u64 kernel_calcNumDenom_intensity_float_param_3,
	.param .u64 kernel_calcNumDenom_intensity_float_param_4,
	.param .u64 kernel_calcNumDenom_intensity_float_param_5,
	.param .u64 kernel_calcNumDenom_intensity_float_param_6,
	.param .u64 kernel_calcNumDenom_intensity_float_param_7,
	.param .u64 kernel_calcNumDenom_intensity_float_param_8,
	.param .u64 kernel_calcNumDenom_intensity_float_param_9,
	.param .u64 kernel_calcNumDenom_intensity_float_param_10,
	.param .u64 kernel_calcNumDenom_intensity_float_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<41>;
	.reg .f32 	%f<49>;
	.reg .s64 	%rd<46>;


	ld.param.u64 	%rd11, [kernel_calcNumDenom_intensity_float_param_0];
	ld.param.u64 	%rd12, [kernel_calcNumDenom_intensity_float_param_1];
	ld.param.u64 	%rd13, [kernel_calcNumDenom_intensity_float_param_2];
	ld.param.u64 	%rd14, [kernel_calcNumDenom_intensity_float_param_3];
	ld.param.u64 	%rd15, [kernel_calcNumDenom_intensity_float_param_4];
	ld.param.u64 	%rd16, [kernel_calcNumDenom_intensity_float_param_5];
	ld.param.u64 	%rd17, [kernel_calcNumDenom_intensity_float_param_6];
	ld.param.u64 	%rd18, [kernel_calcNumDenom_intensity_float_param_7];
	ld.param.u64 	%rd19, [kernel_calcNumDenom_intensity_float_param_8];
	ld.param.u64 	%rd20, [kernel_calcNumDenom_intensity_float_param_9];
	ld.param.u64 	%rd21, [kernel_calcNumDenom_intensity_float_param_10];
	ld.param.u64 	%rd22, [kernel_calcNumDenom_intensity_float_param_11];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r38, %r11, %r12, %r13;
	cvt.s64.s32	%rd45, %r38;
	setp.ge.u64	%p1, %rd45, %rd21;
	@%p1 bra 	BB11_9;

	cvta.to.global.u64 	%rd2, %rd18;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd14;
	cvta.to.global.u64 	%rd5, %rd16;
	cvta.to.global.u64 	%rd6, %rd12;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %nctaid.x;
	mul.lo.s32 	%r1, %r16, %r15;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd15;
	cvta.to.global.u64 	%rd30, %rd11;

BB11_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r39, %r21, %r20, %r22;
	cvt.s64.s32	%rd23, %r39;
	setp.ge.u64	%p2, %rd23, %rd20;
	@%p2 bra 	BB11_8;

	mul.lo.s64 	%rd8, %rd45, %rd20;

BB11_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r40, %r15, %r27, %r29;
	cvt.s64.s32	%rd24, %r40;
	setp.ge.u64	%p3, %rd24, %rd19;
	@%p3 bra 	BB11_7;

	cvt.u64.u32	%rd25, %r39;
	add.s64 	%rd26, %rd25, %rd8;
	cvt.s64.s32 	%rd27, %rd26;
	mul.lo.s64 	%rd9, %rd27, %rd22;

BB11_6:
	cvt.u64.u32	%rd31, %r40;
	add.s64 	%rd32, %rd31, %rd9;
	cvt.s64.s32 	%rd33, %rd32;
	shl.b64 	%rd34, %rd33, 3;
	add.s64 	%rd35, %rd6, %rd34;
	ld.global.v2.f32 	{%f1, %f2}, [%rd35];
	add.s64 	%rd36, %rd5, %rd34;
	ld.global.v2.f32 	{%f3, %f4}, [%rd36];
	mul.f32 	%f7, %f4, %f2;
	fma.rn.f32 	%f10, %f1, %f3, %f7;
	mul.f32 	%f11, %f1, %f4;
	mul.f32 	%f12, %f3, %f2;
	sub.f32 	%f13, %f11, %f12;
	add.s64 	%rd37, %rd28, %rd34;
	ld.global.v2.f32 	{%f14, %f15}, [%rd37];
	add.s64 	%rd38, %rd29, %rd34;
	ld.global.v2.f32 	{%f16, %f17}, [%rd38];
	mul.f32 	%f20, %f17, %f15;
	fma.rn.f32 	%f23, %f14, %f16, %f20;
	mul.f32 	%f24, %f14, %f17;
	mul.f32 	%f25, %f16, %f15;
	sub.f32 	%f26, %f24, %f25;
	add.s64 	%rd39, %rd30, %rd34;
	ld.global.v2.f32 	{%f27, %f28}, [%rd39];
	add.s64 	%rd40, %rd4, %rd34;
	ld.global.v2.f32 	{%f29, %f30}, [%rd40];
	mul.f32 	%f33, %f30, %f28;
	fma.rn.f32 	%f36, %f27, %f29, %f33;
	mul.f32 	%f37, %f27, %f30;
	mul.f32 	%f38, %f29, %f28;
	sub.f32 	%f39, %f37, %f38;
	add.f32 	%f40, %f36, %f36;
	mul.f32 	%f41, %f39, 0f00000000;
	sub.f32 	%f42, %f40, %f41;
	mul.f32 	%f43, %f36, 0f00000000;
	fma.rn.f32 	%f44, %f39, 0f40000000, %f43;
	add.s64 	%rd41, %rd3, %rd34;
	add.f32 	%f45, %f13, %f26;
	sub.f32 	%f46, %f45, %f44;
	add.f32 	%f47, %f10, %f23;
	sub.f32 	%f48, %f47, %f42;
	st.global.v2.f32 	[%rd41], {%f48, %f46};
	add.s64 	%rd42, %rd2, %rd34;
	st.global.v2.f32 	[%rd42], {%f47, %f45};
	add.s32 	%r40, %r1, %r40;
	cvt.s64.s32	%rd43, %r40;
	setp.lt.u64	%p4, %rd43, %rd19;
	@%p4 bra 	BB11_6;

BB11_7:
	mov.u32 	%r34, %nctaid.y;
	mad.lo.s32 	%r39, %r34, %r21, %r39;
	cvt.s64.s32	%rd44, %r39;
	setp.lt.u64	%p5, %rd44, %rd20;
	@%p5 bra 	BB11_4;

BB11_8:
	mov.u32 	%r36, %nctaid.z;
	mad.lo.s32 	%r38, %r36, %r11, %r38;
	cvt.s64.s32	%rd45, %r38;
	setp.lt.u64	%p6, %rd45, %rd21;
	@%p6 bra 	BB11_2;

BB11_9:
	ret;
}

.visible .entry kernel_calcNumDenom_pixels_double(
	.param .u64 kernel_calcNumDenom_pixels_double_param_0,
	.param .u64 kernel_calcNumDenom_pixels_double_param_1,
	.param .u64 kernel_calcNumDenom_pixels_double_param_2,
	.param .u64 kernel_calcNumDenom_pixels_double_param_3,
	.param .u64 kernel_calcNumDenom_pixels_double_param_4,
	.param .u64 kernel_calcNumDenom_pixels_double_param_5,
	.param .u64 kernel_calcNumDenom_pixels_double_param_6,
	.param .u64 kernel_calcNumDenom_pixels_double_param_7,
	.param .u64 kernel_calcNumDenom_pixels_double_param_8,
	.param .u64 kernel_calcNumDenom_pixels_double_param_9,
	.param .u64 kernel_calcNumDenom_pixels_double_param_10,
	.param .u64 kernel_calcNumDenom_pixels_double_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<41>;
	.reg .s64 	%rd<46>;
	.reg .f64 	%fd<62>;


	ld.param.u64 	%rd11, [kernel_calcNumDenom_pixels_double_param_0];
	ld.param.u64 	%rd12, [kernel_calcNumDenom_pixels_double_param_1];
	ld.param.u64 	%rd13, [kernel_calcNumDenom_pixels_double_param_2];
	ld.param.u64 	%rd14, [kernel_calcNumDenom_pixels_double_param_3];
	ld.param.u64 	%rd15, [kernel_calcNumDenom_pixels_double_param_4];
	ld.param.u64 	%rd16, [kernel_calcNumDenom_pixels_double_param_5];
	ld.param.u64 	%rd17, [kernel_calcNumDenom_pixels_double_param_6];
	ld.param.u64 	%rd18, [kernel_calcNumDenom_pixels_double_param_7];
	ld.param.u64 	%rd19, [kernel_calcNumDenom_pixels_double_param_8];
	ld.param.u64 	%rd20, [kernel_calcNumDenom_pixels_double_param_9];
	ld.param.u64 	%rd21, [kernel_calcNumDenom_pixels_double_param_10];
	ld.param.u64 	%rd22, [kernel_calcNumDenom_pixels_double_param_11];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r38, %r11, %r12, %r13;
	cvt.s64.s32	%rd45, %r38;
	setp.ge.u64	%p1, %rd45, %rd21;
	@%p1 bra 	BB12_9;

	cvta.to.global.u64 	%rd2, %rd18;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd14;
	cvta.to.global.u64 	%rd6, %rd11;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %nctaid.x;
	mul.lo.s32 	%r1, %r16, %r15;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd15;
	cvta.to.global.u64 	%rd30, %rd12;

BB12_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r39, %r21, %r20, %r22;
	cvt.s64.s32	%rd23, %r39;
	setp.ge.u64	%p2, %rd23, %rd20;
	@%p2 bra 	BB12_8;

	mul.lo.s64 	%rd8, %rd45, %rd20;

BB12_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r40, %r15, %r27, %r29;
	cvt.s64.s32	%rd24, %r40;
	setp.ge.u64	%p3, %rd24, %rd19;
	@%p3 bra 	BB12_7;

	cvt.u64.u32	%rd25, %r39;
	add.s64 	%rd26, %rd25, %rd8;
	cvt.s64.s32 	%rd27, %rd26;
	mul.lo.s64 	%rd9, %rd27, %rd22;

BB12_6:
	cvt.u64.u32	%rd31, %r40;
	add.s64 	%rd32, %rd31, %rd9;
	cvt.s64.s32 	%rd33, %rd32;
	shl.b64 	%rd34, %rd33, 4;
	add.s64 	%rd35, %rd6, %rd34;
	ld.global.v2.f64 	{%fd1, %fd2}, [%rd35];
	mul.f64 	%fd5, %fd2, 0d0000000000000000;
	fma.rn.f64 	%fd6, %fd1, 0dC000000000000000, %fd5;
	mul.f64 	%fd7, %fd1, 0d0000000000000000;
	mul.f64 	%fd8, %fd2, 0dC000000000000000;
	sub.f64 	%fd9, %fd7, %fd8;
	add.s64 	%rd36, %rd5, %rd34;
	ld.global.v2.f64 	{%fd10, %fd11}, [%rd36];
	mul.f64 	%fd13, %fd6, %fd10;
	mul.f64 	%fd15, %fd9, %fd11;
	sub.f64 	%fd16, %fd13, %fd15;
	mul.f64 	%fd17, %fd9, %fd10;
	fma.rn.f64 	%fd18, %fd6, %fd11, %fd17;
	add.s64 	%rd37, %rd28, %rd34;
	ld.global.v2.f64 	{%fd19, %fd20}, [%rd37];
	add.s64 	%rd38, %rd29, %rd34;
	ld.global.v2.f64 	{%fd21, %fd22}, [%rd38];
	mul.f64 	%fd25, %fd22, %fd20;
	fma.rn.f64 	%fd28, %fd19, %fd21, %fd25;
	mul.f64 	%fd29, %fd19, %fd22;
	mul.f64 	%fd30, %fd21, %fd20;
	sub.f64 	%fd31, %fd29, %fd30;
	add.f64 	%fd32, %fd16, %fd28;
	add.f64 	%fd33, %fd18, %fd31;
	add.s64 	%rd39, %rd30, %rd34;
	ld.global.v2.f64 	{%fd34, %fd35}, [%rd39];
	add.s64 	%rd40, %rd4, %rd34;
	ld.global.v2.f64 	{%fd36, %fd37}, [%rd40];
	mul.f64 	%fd40, %fd37, %fd35;
	fma.rn.f64 	%fd43, %fd34, %fd36, %fd40;
	mul.f64 	%fd44, %fd34, %fd37;
	mul.f64 	%fd45, %fd36, %fd35;
	sub.f64 	%fd46, %fd44, %fd45;
	add.s64 	%rd41, %rd3, %rd34;
	add.f64 	%fd47, %fd33, %fd46;
	add.f64 	%fd48, %fd32, %fd43;
	st.global.v2.f64 	[%rd41], {%fd48, %fd47};
	add.s64 	%rd42, %rd2, %rd34;
	ld.global.v2.f64 	{%fd49, %fd50}, [%rd37];
	ld.global.v2.f64 	{%fd51, %fd52}, [%rd40];
	mul.f64 	%fd55, %fd49, %fd52;
	mul.f64 	%fd58, %fd51, %fd50;
	sub.f64 	%fd59, %fd55, %fd58;
	mul.f64 	%fd60, %fd52, %fd50;
	fma.rn.f64 	%fd61, %fd49, %fd51, %fd60;
	st.global.v2.f64 	[%rd42], {%fd61, %fd59};
	add.s32 	%r40, %r1, %r40;
	cvt.s64.s32	%rd43, %r40;
	setp.lt.u64	%p4, %rd43, %rd19;
	@%p4 bra 	BB12_6;

BB12_7:
	mov.u32 	%r34, %nctaid.y;
	mad.lo.s32 	%r39, %r34, %r21, %r39;
	cvt.s64.s32	%rd44, %r39;
	setp.lt.u64	%p5, %rd44, %rd20;
	@%p5 bra 	BB12_4;

BB12_8:
	mov.u32 	%r36, %nctaid.z;
	mad.lo.s32 	%r38, %r36, %r11, %r38;
	cvt.s64.s32	%rd45, %r38;
	setp.lt.u64	%p6, %rd45, %rd21;
	@%p6 bra 	BB12_2;

BB12_9:
	ret;
}

.visible .entry kernel_calcNumDenom_pixels_float(
	.param .u64 kernel_calcNumDenom_pixels_float_param_0,
	.param .u64 kernel_calcNumDenom_pixels_float_param_1,
	.param .u64 kernel_calcNumDenom_pixels_float_param_2,
	.param .u64 kernel_calcNumDenom_pixels_float_param_3,
	.param .u64 kernel_calcNumDenom_pixels_float_param_4,
	.param .u64 kernel_calcNumDenom_pixels_float_param_5,
	.param .u64 kernel_calcNumDenom_pixels_float_param_6,
	.param .u64 kernel_calcNumDenom_pixels_float_param_7,
	.param .u64 kernel_calcNumDenom_pixels_float_param_8,
	.param .u64 kernel_calcNumDenom_pixels_float_param_9,
	.param .u64 kernel_calcNumDenom_pixels_float_param_10,
	.param .u64 kernel_calcNumDenom_pixels_float_param_11
)
{
	.reg .pred 	%p<7>;
	.reg .s32 	%r<41>;
	.reg .f32 	%f<62>;
	.reg .s64 	%rd<46>;


	ld.param.u64 	%rd11, [kernel_calcNumDenom_pixels_float_param_0];
	ld.param.u64 	%rd12, [kernel_calcNumDenom_pixels_float_param_1];
	ld.param.u64 	%rd13, [kernel_calcNumDenom_pixels_float_param_2];
	ld.param.u64 	%rd14, [kernel_calcNumDenom_pixels_float_param_3];
	ld.param.u64 	%rd15, [kernel_calcNumDenom_pixels_float_param_4];
	ld.param.u64 	%rd16, [kernel_calcNumDenom_pixels_float_param_5];
	ld.param.u64 	%rd17, [kernel_calcNumDenom_pixels_float_param_6];
	ld.param.u64 	%rd18, [kernel_calcNumDenom_pixels_float_param_7];
	ld.param.u64 	%rd19, [kernel_calcNumDenom_pixels_float_param_8];
	ld.param.u64 	%rd20, [kernel_calcNumDenom_pixels_float_param_9];
	ld.param.u64 	%rd21, [kernel_calcNumDenom_pixels_float_param_10];
	ld.param.u64 	%rd22, [kernel_calcNumDenom_pixels_float_param_11];
	mov.u32 	%r11, %ntid.z;
	mov.u32 	%r12, %ctaid.z;
	mov.u32 	%r13, %tid.z;
	mad.lo.s32 	%r38, %r11, %r12, %r13;
	cvt.s64.s32	%rd45, %r38;
	setp.ge.u64	%p1, %rd45, %rd21;
	@%p1 bra 	BB13_9;

	cvta.to.global.u64 	%rd2, %rd18;
	cvta.to.global.u64 	%rd3, %rd17;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd14;
	cvta.to.global.u64 	%rd6, %rd11;
	mov.u32 	%r15, %ntid.x;
	mov.u32 	%r16, %nctaid.x;
	mul.lo.s32 	%r1, %r16, %r15;
	cvta.to.global.u64 	%rd28, %rd13;
	cvta.to.global.u64 	%rd29, %rd15;
	cvta.to.global.u64 	%rd30, %rd12;

BB13_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r39, %r21, %r20, %r22;
	cvt.s64.s32	%rd23, %r39;
	setp.ge.u64	%p2, %rd23, %rd20;
	@%p2 bra 	BB13_8;

	mul.lo.s64 	%rd8, %rd45, %rd20;

BB13_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r40, %r15, %r27, %r29;
	cvt.s64.s32	%rd24, %r40;
	setp.ge.u64	%p3, %rd24, %rd19;
	@%p3 bra 	BB13_7;

	cvt.u64.u32	%rd25, %r39;
	add.s64 	%rd26, %rd25, %rd8;
	cvt.s64.s32 	%rd27, %rd26;
	mul.lo.s64 	%rd9, %rd27, %rd22;

BB13_6:
	cvt.u64.u32	%rd31, %r40;
	add.s64 	%rd32, %rd31, %rd9;
	cvt.s64.s32 	%rd33, %rd32;
	shl.b64 	%rd34, %rd33, 3;
	add.s64 	%rd35, %rd6, %rd34;
	ld.global.v2.f32 	{%f1, %f2}, [%rd35];
	mul.f32 	%f5, %f2, 0f00000000;
	fma.rn.f32 	%f6, %f1, 0fC0000000, %f5;
	mul.f32 	%f7, %f1, 0f00000000;
	mul.f32 	%f8, %f2, 0fC0000000;
	sub.f32 	%f9, %f7, %f8;
	add.s64 	%rd36, %rd5, %rd34;
	ld.global.v2.f32 	{%f10, %f11}, [%rd36];
	mul.f32 	%f13, %f6, %f10;
	mul.f32 	%f15, %f9, %f11;
	sub.f32 	%f16, %f13, %f15;
	mul.f32 	%f17, %f9, %f10;
	fma.rn.f32 	%f18, %f6, %f11, %f17;
	add.s64 	%rd37, %rd28, %rd34;
	ld.global.v2.f32 	{%f19, %f20}, [%rd37];
	add.s64 	%rd38, %rd29, %rd34;
	ld.global.v2.f32 	{%f21, %f22}, [%rd38];
	mul.f32 	%f25, %f22, %f20;
	fma.rn.f32 	%f28, %f19, %f21, %f25;
	mul.f32 	%f29, %f19, %f22;
	mul.f32 	%f30, %f21, %f20;
	sub.f32 	%f31, %f29, %f30;
	add.f32 	%f32, %f16, %f28;
	add.f32 	%f33, %f18, %f31;
	add.s64 	%rd39, %rd30, %rd34;
	ld.global.v2.f32 	{%f34, %f35}, [%rd39];
	add.s64 	%rd40, %rd4, %rd34;
	ld.global.v2.f32 	{%f36, %f37}, [%rd40];
	mul.f32 	%f40, %f37, %f35;
	fma.rn.f32 	%f43, %f34, %f36, %f40;
	mul.f32 	%f44, %f34, %f37;
	mul.f32 	%f45, %f36, %f35;
	sub.f32 	%f46, %f44, %f45;
	add.s64 	%rd41, %rd3, %rd34;
	add.f32 	%f47, %f33, %f46;
	add.f32 	%f48, %f32, %f43;
	st.global.v2.f32 	[%rd41], {%f48, %f47};
	add.s64 	%rd42, %rd2, %rd34;
	ld.global.v2.f32 	{%f49, %f50}, [%rd37];
	ld.global.v2.f32 	{%f51, %f52}, [%rd40];
	mul.f32 	%f55, %f49, %f52;
	mul.f32 	%f58, %f51, %f50;
	sub.f32 	%f59, %f55, %f58;
	mul.f32 	%f60, %f52, %f50;
	fma.rn.f32 	%f61, %f49, %f51, %f60;
	st.global.v2.f32 	[%rd42], {%f61, %f59};
	add.s32 	%r40, %r1, %r40;
	cvt.s64.s32	%rd43, %r40;
	setp.lt.u64	%p4, %rd43, %rd19;
	@%p4 bra 	BB13_6;

BB13_7:
	mov.u32 	%r34, %nctaid.y;
	mad.lo.s32 	%r39, %r34, %r21, %r39;
	cvt.s64.s32	%rd44, %r39;
	setp.lt.u64	%p5, %rd44, %rd20;
	@%p5 bra 	BB13_4;

BB13_8:
	mov.u32 	%r36, %nctaid.z;
	mad.lo.s32 	%r38, %r36, %r11, %r38;
	cvt.s64.s32	%rd45, %r38;
	setp.lt.u64	%p6, %rd45, %rd21;
	@%p6 bra 	BB13_2;

BB13_9:
	ret;
}

.visible .entry kernel_fdshift_double(
	.param .u64 kernel_fdshift_double_param_0,
	.param .u64 kernel_fdshift_double_param_1,
	.param .f64 kernel_fdshift_double_param_2,
	.param .f64 kernel_fdshift_double_param_3,
	.param .f64 kernel_fdshift_double_param_4,
	.param .u64 kernel_fdshift_double_param_5,
	.param .u64 kernel_fdshift_double_param_6,
	.param .u64 kernel_fdshift_double_param_7,
	.param .u64 kernel_fdshift_double_param_8,
	.param .u64 kernel_fdshift_double_param_9,
	.param .u64 kernel_fdshift_double_param_10
)
{
	.local .align 4 .b8 	__local_depot14[8];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<15>;
	.reg .s32 	%r<55>;
	.reg .s64 	%rd<43>;
	.reg .f64 	%fd<121>;


	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd5, [kernel_fdshift_double_param_0];
	ld.param.u64 	%rd6, [kernel_fdshift_double_param_1];
	ld.param.f64 	%fd33, [kernel_fdshift_double_param_2];
	ld.param.f64 	%fd34, [kernel_fdshift_double_param_3];
	ld.param.f64 	%fd35, [kernel_fdshift_double_param_4];
	ld.param.u64 	%rd7, [kernel_fdshift_double_param_5];
	ld.param.u64 	%rd8, [kernel_fdshift_double_param_6];
	ld.param.u64 	%rd9, [kernel_fdshift_double_param_7];
	ld.param.u64 	%rd10, [kernel_fdshift_double_param_8];
	ld.param.u64 	%rd11, [kernel_fdshift_double_param_9];
	ld.param.u64 	%rd12, [kernel_fdshift_double_param_10];
	mov.u32 	%r17, %ntid.z;
	mov.u32 	%r18, %ctaid.z;
	mov.u32 	%r19, %tid.z;
	mad.lo.s32 	%r50, %r17, %r18, %r19;
	cvt.s64.s32	%rd42, %r50;
	setp.ge.u64	%p1, %rd42, %rd10;
	@%p1 bra 	BB14_25;

	cvt.rn.f64.u64	%fd36, %rd7;
	mul.f64 	%fd37, %fd33, 0d401921FB54442D18;
	div.rn.f64 	%fd1, %fd37, %fd36;
	cvt.rn.f64.u64	%fd38, %rd9;
	mul.f64 	%fd39, %fd34, 0d401921FB54442D18;
	div.rn.f64 	%fd2, %fd39, %fd38;
	cvt.rn.f64.u64	%fd40, %rd10;
	mul.f64 	%fd41, %fd35, 0d401921FB54442D18;
	div.rn.f64 	%fd3, %fd41, %fd40;
	cvt.rn.f64.u64	%fd4, %rd12;
	cvta.to.global.u64 	%rd29, %rd5;
	cvta.to.global.u64 	%rd30, %rd6;

BB14_2:
	mov.u32 	%r20, %ctaid.y;
	mov.u32 	%r21, %ntid.y;
	mov.u32 	%r22, %tid.y;
	mad.lo.s32 	%r51, %r21, %r20, %r22;
	cvt.s64.s32	%rd13, %r51;
	setp.ge.u64	%p2, %rd13, %rd9;
	@%p2 bra 	BB14_24;

	mul.lo.s64 	%rd3, %rd42, %rd9;
	cvt.rn.f64.s32	%fd42, %r50;
	mul.f64 	%fd5, %fd3, %fd42;

BB14_4:
	mov.u32 	%r27, %ctaid.x;
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %tid.x;
	mad.lo.s32 	%r52, %r28, %r27, %r29;
	cvt.s64.s32	%rd14, %r52;
	setp.ge.u64	%p3, %rd14, %rd8;
	@%p3 bra 	BB14_23;

	cvt.rn.f64.s32	%fd43, %r51;
	mul.f64 	%fd6, %fd2, %fd43;

BB14_6:
	cvt.rn.f64.s32	%fd44, %r52;
	fma.rn.f64 	%fd45, %fd1, %fd44, %fd6;
	add.f64 	%fd7, %fd45, %fd5;
	abs.f64 	%fd8, %fd7;
	setp.neu.f64	%p4, %fd8, 0d7FF0000000000000;
	mov.f64 	%fd118, %fd7;
	@%p4 bra 	BB14_8;

	mov.f64 	%fd46, 0d0000000000000000;
	mul.rn.f64 	%fd9, %fd7, %fd46;
	mov.f64 	%fd118, %fd9;

BB14_8:
	mov.f64 	%fd10, %fd118;
	add.u64 	%rd15, %SP, 4;
	mul.f64 	%fd47, %fd10, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r53, %fd47;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r53;
	cvt.rn.f64.s32	%fd48, %r53;
	neg.f64 	%fd49, %fd48;
	mov.f64 	%fd50, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd51, %fd49, %fd50, %fd10;
	mov.f64 	%fd52, 0d3C91A62633145C00;
	fma.rn.f64 	%fd53, %fd49, %fd52, %fd51;
	mov.f64 	%fd54, 0d397B839A252049C0;
	fma.rn.f64 	%fd114, %fd49, %fd54, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd10;
	}
	and.b32  	%r35, %r34, 2145386496;
	setp.lt.u32	%p5, %r35, 1105199104;
	@%p5 bra 	BB14_10;

	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd10;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd114, [retval0+0];
	}
	// Callseq End 2
	ld.local.u32 	%r53, [%rd16];

BB14_10:
	add.s32 	%r10, %r53, 1;
	and.b32  	%r36, %r10, 1;
	shl.b32 	%r37, %r36, 3;
	setp.eq.s32	%p6, %r36, 0;
	selp.f64	%fd55, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p6;
	mul.wide.u32 	%rd19, %r37, 8;
	mov.u64 	%rd20, __cudart_sin_cos_coeffs;
	add.s64 	%rd21, %rd19, %rd20;
	ld.const.f64 	%fd56, [%rd21+8];
	mul.rn.f64 	%fd14, %fd114, %fd114;
	fma.rn.f64 	%fd57, %fd55, %fd14, %fd56;
	ld.const.f64 	%fd58, [%rd21+16];
	fma.rn.f64 	%fd59, %fd57, %fd14, %fd58;
	ld.const.f64 	%fd60, [%rd21+24];
	fma.rn.f64 	%fd61, %fd59, %fd14, %fd60;
	ld.const.f64 	%fd62, [%rd21+32];
	fma.rn.f64 	%fd63, %fd61, %fd14, %fd62;
	ld.const.f64 	%fd64, [%rd21+40];
	fma.rn.f64 	%fd65, %fd63, %fd14, %fd64;
	ld.const.f64 	%fd66, [%rd21+48];
	fma.rn.f64 	%fd15, %fd65, %fd14, %fd66;
	fma.rn.f64 	%fd115, %fd15, %fd114, %fd114;
	@%p6 bra 	BB14_12;

	mov.f64 	%fd67, 0d3FF0000000000000;
	fma.rn.f64 	%fd115, %fd15, %fd14, %fd67;

BB14_12:
	and.b32  	%r38, %r10, 2;
	setp.eq.s32	%p7, %r38, 0;
	@%p7 bra 	BB14_14;

	mov.f64 	%fd68, 0d0000000000000000;
	mov.f64 	%fd69, 0dBFF0000000000000;
	fma.rn.f64 	%fd115, %fd115, %fd69, %fd68;

BB14_14:
	mov.f64 	%fd117, %fd7;
	@%p4 bra 	BB14_16;

	mov.f64 	%fd70, 0d0000000000000000;
	mul.rn.f64 	%fd117, %fd7, %fd70;

BB14_16:
	add.u64 	%rd22, %SP, 0;
	mul.f64 	%fd71, %fd117, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r54, %fd71;
	cvta.to.local.u64 	%rd23, %rd22;
	st.local.u32 	[%rd23], %r54;
	cvt.rn.f64.s32	%fd72, %r54;
	neg.f64 	%fd73, %fd72;
	fma.rn.f64 	%fd75, %fd73, %fd50, %fd117;
	fma.rn.f64 	%fd77, %fd73, %fd52, %fd75;
	fma.rn.f64 	%fd119, %fd73, %fd54, %fd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r39}, %fd117;
	}
	and.b32  	%r40, %r39, 2145386496;
	setp.lt.u32	%p9, %r40, 1105199104;
	@%p9 bra 	BB14_18;

	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd117;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd119, [retval0+0];
	}
	// Callseq End 3
	ld.local.u32 	%r54, [%rd23];

BB14_18:
	and.b32  	%r41, %r54, 1;
	shl.b32 	%r42, %r41, 3;
	setp.eq.s32	%p10, %r41, 0;
	selp.f64	%fd79, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	mul.wide.u32 	%rd26, %r42, 8;
	add.s64 	%rd28, %rd26, %rd20;
	ld.const.f64 	%fd80, [%rd28+8];
	mul.rn.f64 	%fd26, %fd119, %fd119;
	fma.rn.f64 	%fd81, %fd79, %fd26, %fd80;
	ld.const.f64 	%fd82, [%rd28+16];
	fma.rn.f64 	%fd83, %fd81, %fd26, %fd82;
	ld.const.f64 	%fd84, [%rd28+24];
	fma.rn.f64 	%fd85, %fd83, %fd26, %fd84;
	ld.const.f64 	%fd86, [%rd28+32];
	fma.rn.f64 	%fd87, %fd85, %fd26, %fd86;
	ld.const.f64 	%fd88, [%rd28+40];
	fma.rn.f64 	%fd89, %fd87, %fd26, %fd88;
	ld.const.f64 	%fd90, [%rd28+48];
	fma.rn.f64 	%fd27, %fd89, %fd26, %fd90;
	fma.rn.f64 	%fd120, %fd27, %fd119, %fd119;
	@%p10 bra 	BB14_20;

	mov.f64 	%fd91, 0d3FF0000000000000;
	fma.rn.f64 	%fd120, %fd27, %fd26, %fd91;

BB14_20:
	and.b32  	%r43, %r54, 2;
	setp.eq.s32	%p11, %r43, 0;
	@%p11 bra 	BB14_22;

	mov.f64 	%fd92, 0d0000000000000000;
	mov.f64 	%fd93, 0dBFF0000000000000;
	fma.rn.f64 	%fd120, %fd120, %fd93, %fd92;

BB14_22:
	div.rn.f64 	%fd94, %fd115, %fd4;
	cvt.u64.u32	%rd31, %r51;
	add.s64 	%rd32, %rd31, %rd3;
	mul.lo.s64 	%rd33, %rd32, %rd11;
	cvt.u64.u32	%rd34, %r52;
	add.s64 	%rd35, %rd34, %rd33;
	cvt.s64.s32 	%rd36, %rd35;
	shl.b64 	%rd37, %rd36, 4;
	add.s64 	%rd38, %rd29, %rd37;
	ld.global.v2.f64 	{%fd95, %fd96}, [%rd38];
	mul.f64 	%fd98, %fd95, %fd94;
	div.rn.f64 	%fd99, %fd120, %fd4;
	mul.f64 	%fd101, %fd96, %fd99;
	mul.f64 	%fd102, %fd96, %fd94;
	sub.f64 	%fd103, %fd98, %fd101;
	fma.rn.f64 	%fd104, %fd95, %fd99, %fd102;
	st.global.v2.f64 	[%rd38], {%fd103, %fd104};
	add.s64 	%rd39, %rd30, %rd37;
	ld.global.v2.f64 	{%fd105, %fd106}, [%rd39];
	mul.f64 	%fd108, %fd105, %fd94;
	mul.f64 	%fd110, %fd106, %fd99;
	mul.f64 	%fd111, %fd106, %fd94;
	sub.f64 	%fd112, %fd108, %fd110;
	fma.rn.f64 	%fd113, %fd105, %fd99, %fd111;
	st.global.v2.f64 	[%rd39], {%fd112, %fd113};
	mov.u32 	%r45, %nctaid.x;
	mad.lo.s32 	%r52, %r45, %r28, %r52;
	cvt.s64.s32	%rd40, %r52;
	setp.lt.u64	%p12, %rd40, %rd8;
	@%p12 bra 	BB14_6;

BB14_23:
	mov.u32 	%r46, %nctaid.y;
	mad.lo.s32 	%r51, %r46, %r21, %r51;
	cvt.s64.s32	%rd41, %r51;
	setp.lt.u64	%p13, %rd41, %rd9;
	@%p13 bra 	BB14_4;

BB14_24:
	mov.u32 	%r48, %nctaid.z;
	mad.lo.s32 	%r50, %r48, %r17, %r50;
	cvt.s64.s32	%rd42, %r50;
	setp.lt.u64	%p14, %rd42, %rd10;
	@%p14 bra 	BB14_2;

BB14_25:
	ret;
}

.visible .entry kernel_fdshift_float(
	.param .u64 kernel_fdshift_float_param_0,
	.param .u64 kernel_fdshift_float_param_1,
	.param .f32 kernel_fdshift_float_param_2,
	.param .f32 kernel_fdshift_float_param_3,
	.param .f32 kernel_fdshift_float_param_4,
	.param .u64 kernel_fdshift_float_param_5,
	.param .u64 kernel_fdshift_float_param_6,
	.param .u64 kernel_fdshift_float_param_7,
	.param .u64 kernel_fdshift_float_param_8,
	.param .u64 kernel_fdshift_float_param_9,
	.param .u64 kernel_fdshift_float_param_10
)
{
	.local .align 4 .b8 	__local_depot15[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<33>;
	.reg .s32 	%r<219>;
	.reg .f32 	%f<133>;
	.reg .s64 	%rd<56>;


	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd18, [kernel_fdshift_float_param_0];
	ld.param.u64 	%rd19, [kernel_fdshift_float_param_1];
	ld.param.f32 	%f44, [kernel_fdshift_float_param_2];
	ld.param.f32 	%f45, [kernel_fdshift_float_param_3];
	ld.param.f32 	%f46, [kernel_fdshift_float_param_4];
	ld.param.u64 	%rd20, [kernel_fdshift_float_param_5];
	ld.param.u64 	%rd21, [kernel_fdshift_float_param_6];
	ld.param.u64 	%rd22, [kernel_fdshift_float_param_7];
	ld.param.u64 	%rd23, [kernel_fdshift_float_param_8];
	ld.param.u64 	%rd24, [kernel_fdshift_float_param_9];
	ld.param.u64 	%rd25, [kernel_fdshift_float_param_10];
	mov.u32 	%r83, %ntid.z;
	mov.u32 	%r84, %ctaid.z;
	mov.u32 	%r85, %tid.z;
	mad.lo.s32 	%r196, %r83, %r84, %r85;
	cvt.s64.s32	%rd51, %r196;
	setp.ge.u64	%p1, %rd51, %rd23;
	@%p1 bra 	BB15_53;

	cvt.rn.f32.u64	%f47, %rd20;
	mul.f32 	%f48, %f44, 0f40C90FDB;
	div.rn.f32 	%f1, %f48, %f47;
	cvt.rn.f32.u64	%f49, %rd22;
	mul.f32 	%f50, %f45, 0f40C90FDB;
	div.rn.f32 	%f2, %f50, %f49;
	cvt.rn.f32.u64	%f51, %rd23;
	mul.f32 	%f52, %f46, 0f40C90FDB;
	div.rn.f32 	%f3, %f52, %f51;
	cvta.to.global.u64 	%rd40, %rd18;
	cvta.to.global.u64 	%rd41, %rd19;

BB15_2:
	mov.u32 	%r86, %ctaid.y;
	mov.u32 	%r87, %ntid.y;
	mov.u32 	%r88, %tid.y;
	mad.lo.s32 	%r197, %r87, %r86, %r88;
	cvt.s64.s32	%rd26, %r197;
	setp.ge.u64	%p2, %rd26, %rd22;
	@%p2 bra 	BB15_52;

	mul.lo.s64 	%rd3, %rd51, %rd22;
	cvt.rn.f32.s32	%f53, %r196;
	mul.f32 	%f4, %f3, %f53;

BB15_4:
	mov.u32 	%r93, %ctaid.x;
	mov.u32 	%r94, %ntid.x;
	mov.u32 	%r95, %tid.x;
	mad.lo.s32 	%r198, %r94, %r93, %r95;
	cvt.s64.s32	%rd27, %r198;
	setp.ge.u64	%p3, %rd27, %rd21;
	@%p3 bra 	BB15_51;

	cvt.u64.u32	%rd28, %r197;
	add.s64 	%rd29, %rd28, %rd3;
	cvt.s64.s32 	%rd4, %rd29;
	cvt.rn.f32.s32	%f54, %r197;
	mul.f32 	%f5, %f2, %f54;
	cvt.rn.f32.u64	%f6, %rd25;

BB15_6:
	cvt.rn.f32.s32	%f55, %r198;
	fma.rn.f32 	%f56, %f1, %f55, %f5;
	add.f32 	%f7, %f56, %f4;
	abs.f32 	%f8, %f7;
	setp.neu.f32	%p4, %f8, 0f7F800000;
	mov.f32 	%f128, %f7;
	@%p4 bra 	BB15_8;

	mov.f32 	%f57, 0f00000000;
	mul.rn.f32 	%f9, %f7, %f57;
	mov.f32 	%f128, %f9;

BB15_8:
	mov.f32 	%f10, %f128;
	mul.f32 	%f58, %f10, 0f3F22F983;
	cvt.rni.s32.f32	%r208, %f58;
	cvt.rn.f32.s32	%f59, %r208;
	neg.f32 	%f60, %f59;
	mov.f32 	%f61, 0f3FC90FDA;
	fma.rn.f32 	%f62, %f60, %f61, %f10;
	mov.f32 	%f63, 0f33A22168;
	fma.rn.f32 	%f64, %f60, %f63, %f62;
	mov.f32 	%f65, 0f27C234C5;
	fma.rn.f32 	%f122, %f60, %f65, %f64;
	abs.f32 	%f66, %f10;
	setp.leu.f32	%p5, %f66, 0f47CE4780;
	@%p5 bra 	BB15_18;

	add.u64 	%rd31, %SP, 0;
	mov.b32 	 %r8, %f10;
	shr.u32 	%r9, %r8, 23;
	bfe.u32 	%r102, %r8, 23, 8;
	add.s32 	%r103, %r102, -128;
	shl.b32 	%r104, %r8, 8;
	or.b32  	%r10, %r104, -2147483648;
	shr.u32 	%r11, %r103, 5;
	cvta.to.local.u64 	%rd53, %rd31;
	mov.u32 	%r200, 0;
	mov.u32 	%r199, %r200;
	mov.u64 	%rd52, __cudart_i2opi_f;

BB15_10:
	.pragma "nounroll";
	ld.const.u32 	%r107, [%rd52];
	// inline asm
	{
	mad.lo.cc.u32   %r105, %r107, %r10, %r200;
	madc.hi.u32     %r106, %r107, %r10,  0;
	}
	// inline asm
	st.local.u32 	[%rd53], %r105;
	add.s64 	%rd53, %rd53, 4;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r199, %r199, 1;
	setp.ne.s32	%p6, %r199, 6;
	mov.u32 	%r200, %r106;
	@%p6 bra 	BB15_10;

	and.b32  	%r16, %r8, -2147483648;
	cvta.to.local.u64 	%rd33, %rd31;
	st.local.u32 	[%rd33+24], %r106;
	mov.u32 	%r110, 6;
	sub.s32 	%r111, %r110, %r11;
	mul.wide.s32 	%rd34, %r111, 4;
	add.s64 	%rd10, %rd33, %rd34;
	ld.local.u32 	%r201, [%rd10];
	ld.local.u32 	%r202, [%rd10+-4];
	and.b32  	%r19, %r9, 31;
	setp.eq.s32	%p7, %r19, 0;
	@%p7 bra 	BB15_13;

	mov.u32 	%r112, 32;
	sub.s32 	%r113, %r112, %r19;
	shr.u32 	%r114, %r202, %r113;
	shl.b32 	%r115, %r201, %r19;
	add.s32 	%r201, %r114, %r115;
	ld.local.u32 	%r116, [%rd10+-8];
	shr.u32 	%r117, %r116, %r113;
	shl.b32 	%r118, %r202, %r19;
	add.s32 	%r202, %r117, %r118;

BB15_13:
	shr.u32 	%r119, %r202, 30;
	shl.b32 	%r120, %r201, 2;
	add.s32 	%r203, %r119, %r120;
	shl.b32 	%r25, %r202, 2;
	shr.u32 	%r121, %r203, 31;
	shr.u32 	%r122, %r201, 30;
	add.s32 	%r26, %r121, %r122;
	setp.eq.s32	%p8, %r121, 0;
	mov.u32 	%r204, %r16;
	mov.u32 	%r205, %r25;
	@%p8 bra 	BB15_15;

	not.b32 	%r123, %r203;
	neg.s32 	%r27, %r25;
	setp.eq.s32	%p9, %r25, 0;
	selp.u32	%r124, 1, 0, %p9;
	add.s32 	%r203, %r124, %r123;
	xor.b32  	%r29, %r16, -2147483648;
	mov.u32 	%r204, %r29;
	mov.u32 	%r205, %r27;

BB15_15:
	mov.u32 	%r31, %r204;
	neg.s32 	%r125, %r26;
	setp.eq.s32	%p10, %r16, 0;
	selp.b32	%r208, %r26, %r125, %p10;
	clz.b32 	%r207, %r203;
	setp.eq.s32	%p11, %r207, 0;
	shl.b32 	%r126, %r203, %r207;
	mov.u32 	%r127, 32;
	sub.s32 	%r128, %r127, %r207;
	shr.u32 	%r129, %r205, %r128;
	add.s32 	%r130, %r129, %r126;
	selp.b32	%r35, %r203, %r130, %p11;
	mov.u32 	%r131, -921707870;
	mul.hi.u32 	%r206, %r35, %r131;
	setp.lt.s32	%p12, %r206, 1;
	@%p12 bra 	BB15_17;

	mul.lo.s32 	%r132, %r35, -921707870;
	shr.u32 	%r133, %r132, 31;
	shl.b32 	%r134, %r206, 1;
	add.s32 	%r206, %r133, %r134;
	add.s32 	%r207, %r207, 1;

BB15_17:
	mov.u32 	%r135, 126;
	sub.s32 	%r136, %r135, %r207;
	shl.b32 	%r137, %r136, 23;
	add.s32 	%r138, %r206, 1;
	shr.u32 	%r139, %r138, 7;
	add.s32 	%r140, %r139, 1;
	shr.u32 	%r141, %r140, 1;
	add.s32 	%r142, %r141, %r137;
	or.b32  	%r143, %r142, %r31;
	mov.b32 	 %f122, %r143;

BB15_18:
	mul.rn.f32 	%f14, %f122, %f122;
	add.s32 	%r42, %r208, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32	%p13, %r43, 0;
	@%p13 bra 	BB15_20;

	mov.f32 	%f67, 0fBAB6061A;
	mov.f32 	%f68, 0f37CCF5CE;
	fma.rn.f32 	%f123, %f68, %f14, %f67;
	bra.uni 	BB15_21;

BB15_20:
	mov.f32 	%f69, 0f3C08839E;
	mov.f32 	%f70, 0fB94CA1F9;
	fma.rn.f32 	%f123, %f70, %f14, %f69;

BB15_21:
	@%p13 bra 	BB15_23;

	mov.f32 	%f71, 0f3D2AAAA5;
	fma.rn.f32 	%f72, %f123, %f14, %f71;
	mov.f32 	%f73, 0fBF000000;
	fma.rn.f32 	%f124, %f72, %f14, %f73;
	bra.uni 	BB15_24;

BB15_23:
	mov.f32 	%f74, 0fBE2AAAA3;
	fma.rn.f32 	%f75, %f123, %f14, %f74;
	mov.f32 	%f76, 0f00000000;
	fma.rn.f32 	%f124, %f75, %f14, %f76;

BB15_24:
	fma.rn.f32 	%f125, %f124, %f122, %f122;
	@%p13 bra 	BB15_26;

	mov.f32 	%f77, 0f3F800000;
	fma.rn.f32 	%f125, %f124, %f14, %f77;

BB15_26:
	and.b32  	%r144, %r42, 2;
	setp.eq.s32	%p16, %r144, 0;
	@%p16 bra 	BB15_28;

	mov.f32 	%f78, 0f00000000;
	mov.f32 	%f79, 0fBF800000;
	fma.rn.f32 	%f125, %f125, %f79, %f78;

BB15_28:
	mov.f32 	%f127, %f7;
	@%p4 bra 	BB15_30;

	mov.f32 	%f80, 0f00000000;
	mul.rn.f32 	%f127, %f7, %f80;

BB15_30:
	mul.f32 	%f81, %f127, 0f3F22F983;
	cvt.rni.s32.f32	%r218, %f81;
	cvt.rn.f32.s32	%f82, %r218;
	neg.f32 	%f83, %f82;
	fma.rn.f32 	%f85, %f83, %f61, %f127;
	fma.rn.f32 	%f87, %f83, %f63, %f85;
	fma.rn.f32 	%f129, %f83, %f65, %f87;
	abs.f32 	%f89, %f127;
	setp.leu.f32	%p18, %f89, 0f47CE4780;
	@%p18 bra 	BB15_40;

	add.u64 	%rd36, %SP, 0;
	mov.b32 	 %r45, %f127;
	shr.u32 	%r46, %r45, 23;
	bfe.u32 	%r147, %r45, 23, 8;
	add.s32 	%r148, %r147, -128;
	shl.b32 	%r149, %r45, 8;
	or.b32  	%r47, %r149, -2147483648;
	shr.u32 	%r48, %r148, 5;
	cvta.to.local.u64 	%rd55, %rd36;
	mov.u32 	%r210, 0;
	mov.u32 	%r209, %r210;
	mov.u64 	%rd54, __cudart_i2opi_f;

BB15_32:
	.pragma "nounroll";
	ld.const.u32 	%r152, [%rd54];
	// inline asm
	{
	mad.lo.cc.u32   %r150, %r152, %r47, %r210;
	madc.hi.u32     %r151, %r152, %r47,  0;
	}
	// inline asm
	st.local.u32 	[%rd55], %r150;
	add.s64 	%rd55, %rd55, 4;
	add.s64 	%rd54, %rd54, 4;
	add.s32 	%r209, %r209, 1;
	setp.ne.s32	%p19, %r209, 6;
	mov.u32 	%r210, %r151;
	@%p19 bra 	BB15_32;

	and.b32  	%r53, %r45, -2147483648;
	cvta.to.local.u64 	%rd38, %rd36;
	st.local.u32 	[%rd38+24], %r151;
	mov.u32 	%r155, 6;
	sub.s32 	%r156, %r155, %r48;
	mul.wide.s32 	%rd39, %r156, 4;
	add.s64 	%rd16, %rd38, %rd39;
	ld.local.u32 	%r211, [%rd16];
	ld.local.u32 	%r212, [%rd16+-4];
	and.b32  	%r56, %r46, 31;
	setp.eq.s32	%p20, %r56, 0;
	@%p20 bra 	BB15_35;

	mov.u32 	%r157, 32;
	sub.s32 	%r158, %r157, %r56;
	shr.u32 	%r159, %r212, %r158;
	shl.b32 	%r160, %r211, %r56;
	add.s32 	%r211, %r159, %r160;
	ld.local.u32 	%r161, [%rd16+-8];
	shr.u32 	%r162, %r161, %r158;
	shl.b32 	%r163, %r212, %r56;
	add.s32 	%r212, %r162, %r163;

BB15_35:
	shr.u32 	%r164, %r212, 30;
	shl.b32 	%r165, %r211, 2;
	add.s32 	%r213, %r164, %r165;
	shl.b32 	%r62, %r212, 2;
	shr.u32 	%r166, %r213, 31;
	shr.u32 	%r167, %r211, 30;
	add.s32 	%r63, %r166, %r167;
	setp.eq.s32	%p21, %r166, 0;
	mov.u32 	%r214, %r53;
	mov.u32 	%r215, %r62;
	@%p21 bra 	BB15_37;

	not.b32 	%r168, %r213;
	neg.s32 	%r64, %r62;
	setp.eq.s32	%p22, %r62, 0;
	selp.u32	%r169, 1, 0, %p22;
	add.s32 	%r213, %r169, %r168;
	xor.b32  	%r66, %r53, -2147483648;
	mov.u32 	%r214, %r66;
	mov.u32 	%r215, %r64;

BB15_37:
	mov.u32 	%r68, %r214;
	neg.s32 	%r170, %r63;
	setp.eq.s32	%p23, %r53, 0;
	selp.b32	%r218, %r63, %r170, %p23;
	clz.b32 	%r217, %r213;
	setp.eq.s32	%p24, %r217, 0;
	shl.b32 	%r171, %r213, %r217;
	mov.u32 	%r172, 32;
	sub.s32 	%r173, %r172, %r217;
	shr.u32 	%r174, %r215, %r173;
	add.s32 	%r175, %r174, %r171;
	selp.b32	%r72, %r213, %r175, %p24;
	mov.u32 	%r176, -921707870;
	mul.hi.u32 	%r216, %r72, %r176;
	setp.lt.s32	%p25, %r216, 1;
	@%p25 bra 	BB15_39;

	mul.lo.s32 	%r177, %r72, -921707870;
	shr.u32 	%r178, %r177, 31;
	shl.b32 	%r179, %r216, 1;
	add.s32 	%r216, %r178, %r179;
	add.s32 	%r217, %r217, 1;

BB15_39:
	mov.u32 	%r180, 126;
	sub.s32 	%r181, %r180, %r217;
	shl.b32 	%r182, %r181, 23;
	add.s32 	%r183, %r216, 1;
	shr.u32 	%r184, %r183, 7;
	add.s32 	%r185, %r184, 1;
	shr.u32 	%r186, %r185, 1;
	add.s32 	%r187, %r186, %r182;
	or.b32  	%r188, %r187, %r68;
	mov.b32 	 %f129, %r188;

BB15_40:
	div.rn.f32 	%f31, %f125, %f6;
	mul.rn.f32 	%f32, %f129, %f129;
	and.b32  	%r79, %r218, 1;
	setp.eq.s32	%p26, %r79, 0;
	@%p26 bra 	BB15_42;

	mov.f32 	%f90, 0fBAB6061A;
	mov.f32 	%f91, 0f37CCF5CE;
	fma.rn.f32 	%f130, %f91, %f32, %f90;
	bra.uni 	BB15_43;

BB15_42:
	mov.f32 	%f92, 0f3C08839E;
	mov.f32 	%f93, 0fB94CA1F9;
	fma.rn.f32 	%f130, %f93, %f32, %f92;

BB15_43:
	@%p26 bra 	BB15_45;

	mov.f32 	%f94, 0f3D2AAAA5;
	fma.rn.f32 	%f95, %f130, %f32, %f94;
	mov.f32 	%f96, 0fBF000000;
	fma.rn.f32 	%f131, %f95, %f32, %f96;
	bra.uni 	BB15_46;

BB15_45:
	mov.f32 	%f97, 0fBE2AAAA3;
	fma.rn.f32 	%f98, %f130, %f32, %f97;
	mov.f32 	%f99, 0f00000000;
	fma.rn.f32 	%f131, %f98, %f32, %f99;

BB15_46:
	fma.rn.f32 	%f132, %f131, %f129, %f129;
	@%p26 bra 	BB15_48;

	mov.f32 	%f100, 0f3F800000;
	fma.rn.f32 	%f132, %f131, %f32, %f100;

BB15_48:
	and.b32  	%r189, %r218, 2;
	setp.eq.s32	%p29, %r189, 0;
	@%p29 bra 	BB15_50;

	mov.f32 	%f101, 0f00000000;
	mov.f32 	%f102, 0fBF800000;
	fma.rn.f32 	%f132, %f132, %f102, %f101;

BB15_50:
	mul.lo.s64 	%rd42, %rd4, %rd24;
	cvt.u64.u32	%rd43, %r198;
	add.s64 	%rd44, %rd43, %rd42;
	cvt.s64.s32 	%rd45, %rd44;
	shl.b64 	%rd46, %rd45, 3;
	add.s64 	%rd47, %rd40, %rd46;
	ld.global.v2.f32 	{%f103, %f104}, [%rd47];
	mul.f32 	%f106, %f103, %f31;
	div.rn.f32 	%f107, %f132, %f6;
	mul.f32 	%f109, %f104, %f107;
	mul.f32 	%f110, %f104, %f31;
	fma.rn.f32 	%f111, %f103, %f107, %f110;
	sub.f32 	%f112, %f106, %f109;
	st.global.v2.f32 	[%rd47], {%f112, %f111};
	add.s64 	%rd48, %rd41, %rd46;
	ld.global.v2.f32 	{%f113, %f114}, [%rd48];
	mul.f32 	%f116, %f113, %f31;
	mul.f32 	%f118, %f114, %f107;
	mul.f32 	%f119, %f114, %f31;
	fma.rn.f32 	%f120, %f113, %f107, %f119;
	sub.f32 	%f121, %f116, %f118;
	st.global.v2.f32 	[%rd48], {%f121, %f120};
	mov.u32 	%r191, %nctaid.x;
	mad.lo.s32 	%r198, %r191, %r94, %r198;
	cvt.s64.s32	%rd49, %r198;
	setp.lt.u64	%p30, %rd49, %rd21;
	@%p30 bra 	BB15_6;

BB15_51:
	mov.u32 	%r192, %nctaid.y;
	mad.lo.s32 	%r197, %r192, %r87, %r197;
	cvt.s64.s32	%rd50, %r197;
	setp.lt.u64	%p31, %rd50, %rd22;
	@%p31 bra 	BB15_4;

BB15_52:
	mov.u32 	%r194, %nctaid.z;
	mad.lo.s32 	%r196, %r194, %r83, %r196;
	cvt.s64.s32	%rd51, %r196;
	setp.lt.u64	%p32, %rd51, %rd23;
	@%p32 bra 	BB15_2;

BB15_53:
	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot16[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .s32 	%r<42>;
	.reg .s64 	%rd<99>;
	.reg .f64 	%fd<5>;


	mov.u64 	%SPL, __local_depot16;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd38, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB16_14;

	add.s32 	%r15, %r4, -1024;
	shr.u32 	%r16, %r15, 6;
	mov.u32 	%r17, 15;
	sub.s32 	%r5, %r17, %r16;
	mov.u32 	%r18, 19;
	sub.s32 	%r19, %r18, %r16;
	mov.u32 	%r20, 18;
	min.s32 	%r6, %r20, %r19;
	setp.lt.s32	%p2, %r5, %r6;
	mov.u64 	%rd92, %rd38;
	@%p2 bra 	BB16_3;

	mov.u64 	%rd93, 0;
	bra.uni 	BB16_5;

BB16_3:
	mov.b64 	 %rd41, %fd4;
	shl.b64 	%rd42, %rd41, 11;
	or.b64  	%rd3, %rd42, -9223372036854775808;
	bfe.u32 	%r21, %r1, 20, 11;
	add.s32 	%r22, %r21, -1024;
	shr.u32 	%r23, %r22, 6;
	sub.s32 	%r25, %r17, %r23;
	mul.wide.s32 	%rd43, %r25, 8;
	mov.u64 	%rd44, __cudart_i2opi_d;
	add.s64 	%rd90, %rd44, %rd43;
	mov.u64 	%rd93, 0;
	mov.u64 	%rd91, %rd38;
	mov.u64 	%rd89, %rd38;
	mov.u32 	%r39, %r5;

BB16_4:
	.pragma "nounroll";
	mov.u32 	%r7, %r39;
	mov.u64 	%rd6, %rd89;
	ld.const.u64 	%rd47, [%rd90];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd47;    
	mov.b64         {blo,bhi}, %rd3;    
	mov.b64         {clo,chi}, %rd93;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd45, {r0,r1};      
	mov.b64         %rd46, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd91], %rd45;
	add.s32 	%r8, %r7, 1;
	sub.s32 	%r26, %r8, %r5;
	mul.wide.s32 	%rd50, %r26, 8;
	add.s64 	%rd91, %rd38, %rd50;
	add.s64 	%rd90, %rd90, 8;
	add.s64 	%rd92, %rd6, 8;
	setp.lt.s32	%p3, %r8, %r6;
	mov.u64 	%rd13, %rd92;
	mov.u64 	%rd93, %rd46;
	mov.u64 	%rd89, %rd13;
	mov.u32 	%r39, %r8;
	@%p3 bra 	BB16_4;

BB16_5:
	st.local.u64 	[%rd92], %rd93;
	ld.local.u64 	%rd94, [%rd38+16];
	ld.local.u64 	%rd95, [%rd38+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB16_7;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r9;
	shl.b64 	%rd51, %rd95, %r9;
	shr.u64 	%rd52, %rd94, %r28;
	or.b64  	%rd95, %rd51, %rd52;
	shl.b64 	%rd53, %rd94, %r9;
	ld.local.u64 	%rd54, [%rd38+8];
	shr.u64 	%rd55, %rd54, %r28;
	or.b64  	%rd94, %rd55, %rd53;

BB16_7:
	cvta.to.local.u64 	%rd56, %rd37;
	shr.u64 	%rd57, %rd95, 62;
	cvt.u32.u64	%r29, %rd57;
	shr.u64 	%rd58, %rd94, 62;
	shl.b64 	%rd59, %rd95, 2;
	or.b64  	%rd97, %rd59, %rd58;
	shl.b64 	%rd96, %rd94, 2;
	shr.u64 	%rd60, %rd95, 61;
	cvt.u32.u64	%r30, %rd60;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	st.local.u32 	[%rd56], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB16_9;

	mov.u64 	%rd64, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd64;
	mov.b64         {a2,a3}, %rd64;
	mov.b64         {b0,b1}, %rd96;
	mov.b64         {b2,b3}, %rd97;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd61, {r0,r1};
	mov.b64         %rd62, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;
	mov.u64 	%rd97, %rd62;
	mov.u64 	%rd96, %rd61;

BB16_9:
	clz.b64 	%r41, %rd97;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB16_11;

	shl.b64 	%rd67, %rd97, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd68, %rd96, %r36;
	or.b64  	%rd97, %rd68, %rd67;

BB16_11:
	mov.u64 	%rd72, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd97;   
	mov.b64         {blo,bhi}, %rd72;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd69, {r0,r1};     
	mov.b64         %rd70, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd70, 1;
	mov.u64 	%rd98, %rd70;
	@%p8 bra 	BB16_13;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd69;
	mov.b64         {a2,a3}, %rd70;
	mov.b64         {b0,b1}, %rd69;
	mov.b64         {b2,b3}, %rd70;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd73, {r0,r1};
	mov.b64         %rd74, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;
	mov.u64 	%rd98, %rd74;

BB16_13:
	cvt.u64.u32	%rd79, %r40;
	shl.b64 	%rd80, %rd79, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd81, %r38;
	shl.b64 	%rd82, %rd81, 52;
	add.s64 	%rd83, %rd98, 1;
	shr.u64 	%rd84, %rd83, 10;
	add.s64 	%rd85, %rd84, 1;
	shr.u64 	%rd86, %rd85, 1;
	add.s64 	%rd87, %rd86, %rd82;
	or.b64  	%rd88, %rd87, %rd80;
	mov.b64 	 %fd4, %rd88;

BB16_14:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}


